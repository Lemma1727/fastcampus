{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6-2. Attention-based RNN Seq2Seq.ipynb","provenance":[],"authorship_tag":"ABX9TyNgDkq+XEh5qVckK42zYGFv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c5c5bd577ee244ce92b8286e3a4ae12c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eb73c14b912b4d84be558a54dc3794a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d6a1e9c1fad34303a2c5e4c28ac3c80f","IPY_MODEL_463477177d3b4d4ebba7ae1d26f79b05","IPY_MODEL_9b7717f944eb41e6b5b190b27449721a"]}},"eb73c14b912b4d84be558a54dc3794a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d6a1e9c1fad34303a2c5e4c28ac3c80f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d0bde53140324cbc8b5943843a6cc29e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0af4daab22f240818d294cde9f19b4ce"}},"463477177d3b4d4ebba7ae1d26f79b05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ffed1d1b3d0d4d33b68ae6974cb5b410","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cda42c7ecbbf4aca9abef100f965e06c"}},"9b7717f944eb41e6b5b190b27449721a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0582e8b9848f41b6b8488486439ed637","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9f627137eaf47c1ab7b6bc4460e98f5"}},"d0bde53140324cbc8b5943843a6cc29e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0af4daab22f240818d294cde9f19b4ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffed1d1b3d0d4d33b68ae6974cb5b410":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cda42c7ecbbf4aca9abef100f965e06c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0582e8b9848f41b6b8488486439ed637":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c9f627137eaf47c1ab7b6bc4460e98f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"zL2f6Rc-JG54","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1637673060569,"user_tz":-540,"elapsed":225920,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"f0ce60b2-c28e-4b47-a582-f81eaf3106b4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","import sys\n","from datetime import datetime\n","\n","drive_project_root = '/content/drive/MyDrive/#fastcampus'\n","sys.path.append(drive_project_root)\n","!pip install -r '/content/drive/MyDrive/#fastcampus/requirements.txt'"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n","\u001b[?25hCollecting pytorch-lightning==1.3.8\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[K     |████████████████████████████████| 813 kB 34.0 MB/s \n","\u001b[?25hCollecting torch-optimizer==0.1.0\n","  Downloading torch_optimizer-0.1.0-py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 978 kB/s \n","\u001b[?25hCollecting hydra-core==1.1\n","  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 45.9 MB/s \n","\u001b[?25hCollecting wandb==0.11.1\n","  Downloading wandb-0.11.1-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 35.5 MB/s \n","\u001b[?25hCollecting torchtext==0.10.0\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 4.5 MB/s \n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 50.9 MB/s \n","\u001b[?25hRequirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (2.2.4)\n","Collecting efficientnet_pytorch==0.7.1\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","Requirement already satisfied: tensorflow==2.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (2.7.0)\n","Collecting tensorflow-addons==0.15.0\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 39.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 1)) (3.10.0.2)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 44.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (1.19.5)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (21.3)\n","Requirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (7.1.2)\n","Collecting PyYAML<=5.4.1,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 36.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (4.62.3)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (2.7.0)\n","Collecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[K     |████████████████████████████████| 329 kB 47.3 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 49.4 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Collecting pytorch-ranger>=0.1.1\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Collecting omegaconf==2.1.*\n","  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 3.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 4)) (5.4.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (5.4.8)\n","Collecting graphql-core>=2.3.0\n","  Downloading graphql_core-3.1.6-py3-none-any.whl (189 kB)\n","\u001b[K     |████████████████████████████████| 189 kB 36.0 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (3.17.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (2.23.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 43.3 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (1.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (2.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (0.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (57.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (3.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (1.1.3)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (2.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (2.7.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.42.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (0.22.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (0.37.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (0.12.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (3.1.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.13.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.1.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (2.7.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (12.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (0.2.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons==0.15.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 11)) (2.7.1)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (4.8.2)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 37.0 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 10)) (1.5.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 8)) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb==0.11.1->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (3.1.1)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 47.5 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (2.0.7)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 46.4 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r /content/drive/MyDrive/#fastcampus/requirements.txt (line 2)) (21.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 47.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Building wheels for collected packages: efficientnet-pytorch, antlr4-python3-runtime, future, pathtools\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=1e94c0d45f1d042606bd668c7e0a8288063a462a414324f188a7f680ccfc07c6\n","  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=8a85b895456ca25984885e63b68d2943e61f39456f1dbb60b7714a6b03bf0cee\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=f855fa077cda5fc0d265d1e144d8091e5acbcda0e024a975d564b1de8d10981a\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=06d7ff7f9afbec54d9c295956dde673e498e704a3eb78d5e333fcf492fb2a60c\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built efficientnet-pytorch antlr4-python3-runtime future pathtools\n","Installing collected packages: multidict, frozenlist, yarl, smmap, asynctest, async-timeout, aiosignal, torch, PyYAML, gitdb, fsspec, antlr4-python3-runtime, aiohttp, torchmetrics, shortuuid, sentry-sdk, pytorch-ranger, pyDeprecate, pathtools, omegaconf, graphql-core, GitPython, future, docker-pycreds, configparser, wandb, torchvision, torchtext, torch-optimizer, tensorflow-addons, pytorch-lightning, hydra-core, efficientnet-pytorch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.24 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.1 asynctest-0.13.0 configparser-5.1.0 docker-pycreds-0.4.0 efficientnet-pytorch-0.7.1 frozenlist-1.2.0 fsspec-2021.11.0 future-0.18.2 gitdb-4.0.9 graphql-core-3.1.6 hydra-core-1.1.0 multidict-5.2.0 omegaconf-2.1.1 pathtools-0.1.2 pyDeprecate-0.3.0 pytorch-lightning-1.3.8 pytorch-ranger-0.1.1 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 tensorflow-addons-0.15.0 torch-1.9.0 torch-optimizer-0.1.0 torchmetrics-0.6.0 torchtext-0.10.0 torchvision-0.10.0 wandb-0.11.1 yarl-1.7.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"IIO5LG2wl70Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673060939,"user_tz":-540,"elapsed":388,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"e0edfab6-87ca-4371-9041-bd58c0e9a1d3"},"source":["gpu_info = !nvidia-smi\n","gpu_info = \"\\n\".join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Select the Runtime > \"change runtime type\" menu to enable a GPU accelerator, ')\n","    print('and then re-execurte this cell.')\n","else:\n","    print(gpu_info)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Nov 23 13:10:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"35FDJKXxJ_to","executionInfo":{"status":"ok","timestamp":1637673064820,"user_tz":-540,"elapsed":3883,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# For data loading\n","from typing import List\n","from typing import Dict\n","from typing import Union\n","from typing import Any\n","from typing import Optional\n","from typing import Iterable\n","from typing import Callable\n","from abc import abstractmethod\n","from abc import ABC\n","from datetime import datetime\n","from functools import partial\n","from collections import Counter\n","from collections import OrderedDict\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","import pytorch_lightning as pl\n","from pprint import pprint\n","\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.datasets import Multi30k\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.data.functional import to_map_style_dataset\n","from torchtext.vocab import Vocab, build_vocab_from_iterator, vocab\n","import spacy\n","\n","# For configuration\n","from omegaconf import DictConfig\n","from omegaconf import OmegaConf\n","import hydra\n","from hydra.core.config_store import ConfigStore\n","\n","# For logger\n","from torch.utils.tensorboard import SummaryWriter\n","import wandb\n","os.environ[\"WANDB_START_METHOD\"]=\"thread\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qw2Pp_hxO-Iw","executionInfo":{"status":"ok","timestamp":1637673065210,"user_tz":-540,"elapsed":395,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["from data_utils import dataset_split\n","from config_utils import flatten_dict\n","from config_utils import register_config\n","from config_utils import configure_optimizers_from_cfg\n","from config_utils import get_loggers\n","from config_utils import get_callbacks"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQCJwE0bKa2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673096735,"user_tz":-540,"elapsed":31529,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"a692a729-bae3-4d53-fc22-3ca69280768f"},"source":["# download spacy data.\n","!python -m spacy download en\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download de\n","!python -m spacy download de_core_news_sm\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n","\u001b[K     |████████████████████████████████| 12.0 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Collecting en_core_web_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n","\u001b[K     |████████████████████████████████| 12.0 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","Collecting de_core_news_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n","\u001b[K     |████████████████████████████████| 14.9 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Building wheels for collected packages: de-core-news-sm\n","  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-py3-none-any.whl size=14907055 sha256=53a1fe494454b43d796f307d95ac1d2f11472e0b597b9824bda43488767a3a9e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-k2z7u37h/wheels/00/66/69/cb6c921610087d2cab339062345098e30a5ceb665360e7b32a\n","Successfully built de-core-news-sm\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n","Collecting de_core_news_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9 MB)\n","\u001b[K     |████████████████████████████████| 14.9 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n"]}]},{"cell_type":"code","metadata":{"id":"p3tQ9h4ZdLim","executionInfo":{"status":"ok","timestamp":1637673096736,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["data_spacy_de_en_cfg = {\n","    \"name\": \"spacy_de_en\",\n","    \"data_root\": os.path.join(os.getcwd(), \"data\"),\n","    'tokenizer': \"spacy\",\n","    \"src_lang\": \"de\",\n","    \"tgt_lang\": \"en\",\n","    \"src_index\": 0,\n","    \"tgt_index\": 1,\n","    \"vocab\": {\n","        \"special_symbol2index\": {\n","            \"<unk>\": 0,\n","            \"<pad>\": 1,\n","            \"<bos>\": 2,\n","            \"<eos>\": 3,\n","            \n","        },\n","        \"special_first\": True,\n","        \"min_freq\": 2\n","    }\n","}\n","\n","data_cfg = OmegaConf.create(data_spacy_de_en_cfg)\n","# print(OmegaConf.to_yaml(data_cfg))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_Qeg417e7Pm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673100006,"user_tz":-540,"elapsed":3275,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"ccf9cb5d-5ffb-4d9e-bfff-57912fb32f7e"},"source":["train_data, vaild_data, test_data = Multi30k(data_cfg.data_root)\n","test_data = to_map_style_dataset(test_data)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 1.28MB/s]\n","validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 217kB/s]\n","mmt16_task1_test.tar.gz: 100%|██████████| 43.9k/43.9k [00:00<00:00, 213kB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"bGcXL8ecfSKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673100405,"user_tz":-540,"elapsed":414,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"53a3c5e4-028d-404c-ab7b-d900b9a98956"},"source":["for i in test_data:\n","    print(i)\n","    break"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\\n', 'A man in an orange hat starring at something.\\n')\n"]}]},{"cell_type":"code","metadata":{"id":"9TSP_X0Rf9VW","executionInfo":{"status":"ok","timestamp":1637673102562,"user_tz":-540,"elapsed":2159,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# 1. token_transform (token ...)\n","\n","def get_token_transform(data_cfg: DictConfig) -> dict:\n","    token_transform: dict = {}\n","    token_transform[data_cfg.src_lang] = get_tokenizer(\n","        data_cfg.tokenizer, language=data_cfg.src_lang\n","    )\n","    token_transform[data_cfg.tgt_lang] = get_tokenizer(\n","        data_cfg.tokenizer, language=data_cfg.tgt_lang\n","    )\n","    return token_transform\n","\n","token_transform = get_token_transform(data_cfg)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvXdvgOkgCKE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673111823,"user_tz":-540,"elapsed":9264,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"adb2ab4f-8d94-48bc-9bdc-d8d28bbbe676"},"source":["# 2. vocab_transform\n","def yield_tokens(\n","    data_iter: Iterable, lang: str, lang2index: Dict[str, int],\n",") -> List[str]:\n","    \"\"\"help function to yield list of tokens\"\"\"\n","    for data_sample in data_iter:\n","        yield token_transform[lang](data_sample[lang2index[lang]])\n","\n","\n","def get_vocab_transform(data_cfg: DictConfig) -> dict:\n","    vocab_transform: dict = {}\n","    for ln in [data_cfg.src_lang, data_cfg.tgt_lang]:\n","        train_iter = Multi30k(\n","            split=\"train\", language_pair=(data_cfg.src_lang, data_cfg.tgt_lang)\n","\n","        )\n","        \n","        # create torchtext's Vocab object\n","        vocab_transform[ln] = build_vocab_from_iterator(\n","            yield_tokens(\n","                train_iter,\n","                ln,\n","                {\n","                    data_cfg.src_lang: data_cfg.src_index,\n","                    data_cfg.tgt_lang: data_cfg.tgt_index\n","                }\n","            ),\n","            min_freq=data_cfg.vocab.min_freq,\n","            specials=list(data_cfg.vocab.special_symbol2index.keys()),\n","            special_first=True\n","\n","        )\n","\n","    # set UNKNOWN as the default index. --> index가 unknown으로 return  : token이 찾아지지 않은 경우 !\n","    # 만양에 세팅되지 않으면, runtime error가 날 수 있다!\n","    for ln in [data_cfg.src_lang, data_cfg.tgt_lang]:\n","        vocab_transform[ln].set_default_index(data_cfg.vocab.special_symbol2index[\"<unk>\"])\n","    return vocab_transform\n"," \n","vocab_transform = get_vocab_transform(data_cfg)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 1.14MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"15XpkacvC0ld","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673111824,"user_tz":-540,"elapsed":26,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"2d88c2f1-dfb7-4138-91be-ac82d672e633"},"source":["print(vocab_transform[\"de\"][\"<bos>\"])\n","print(vocab_transform[\"en\"][\"hello\"], vocab_transform[\"en\"][\"world\"])"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","5466 1871\n"]}]},{"cell_type":"code","metadata":{"id":"d8b7HMM1gF4t","executionInfo":{"status":"ok","timestamp":1637673111825,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# 3 integrated transforms\n","# --> text_transform: [token_transform --> vocab_transform -->torch.tensor transform]\n","\n","# helper function for collate_fn\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# convert to torch.tensor with bos & eos\n","def tensor_transform(token_ids: List[int], bos_index: int, eos_index: int):\n","    return torch.cat(\n","        (torch.tensor([bos_index]), torch.tensor(token_ids), torch.tensor([eos_index]))\n","    )\n","\n","# src & tgt lang language text_transforms to convert raw strings --> tensor indices\n","def get_text_transform(data_cfg: DictConfig):\n","    text_transform = {}\n","    for ln in [data_cfg.src_lang, data_cfg.tgt_lang]:\n","        text_transform[ln] = sequential_transforms(\n","            token_transform[ln],\n","            vocab_transform[ln],\n","            partial(\n","                tensor_transform,\n","                bos_index=data_cfg.vocab.special_symbol2index[\"<bos>\"],\n","                eos_index=data_cfg.vocab.special_symbol2index[\"<eos>\"]\n","            )\n","        )\n","    return text_transform\n","\n","text_transform = get_text_transform(data_cfg)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnuSw7WlCr5a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673111825,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"aac8516e-8e87-43ca-a938-8f053b9cf38e"},"source":["print(text_transform['en'](\"hello\"))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([   2, 5466,    3])\n"]}]},{"cell_type":"code","metadata":{"id":"SwOtRipjgxst","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673113146,"user_tz":-540,"elapsed":1331,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"ca479291-8169-4991-ef12-16db5b65362f"},"source":["# 4 collate_fn -->batch를 전처리 할까?\n","def collate_fn(batch, data_cfg: DictConfig):\n","    src_batch, tgt_batch = [], []\n","\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[data_cfg.src_lang](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[data_cfg.tgt_lang](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=data_cfg.vocab.special_symbol2index['<pad>'])\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=data_cfg.vocab.special_symbol2index['<pad>'])\n","    return src_batch, tgt_batch\n","\n","def get_collate_fn(cfg: DictConfig):\n","    return partial(collate_fn, data_cfg=cfg.data)\n","\n","# 5 data loader\n","def get_multi30k_dataloader(split_mode: str, language_pair: tuple, batch_size: int, collate_fn):\n","\n","    iter = Multi30k(split=split_mode, language_pair=language_pair)\n","    dataset = to_map_style_dataset(iter)\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n","    return dataloader\n","\n","test_dataloader = get_multi30k_dataloader(\"test\", (data_cfg.src_lang, data_cfg.tgt_lang), 3, collate_fn=partial(collate_fn, data_cfg=data_cfg))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["mmt16_task1_test.tar.gz: 100%|██████████| 43.9k/43.9k [00:00<00:00, 205kB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"_1AObd1SCabC","executionInfo":{"status":"ok","timestamp":1637673113147,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"zp6kXTyCJY2N","executionInfo":{"status":"ok","timestamp":1637673113148,"user_tz":-540,"elapsed":7,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["def _text_postprocessing(res: List[str]) -> str:\n","    if \"<eos>\" in res:\n","        res = res[:res.index(\"<eos>\")]\n","    if \"<pad>\" in res:\n","        res = res[:res.index(\"<pad>\")]\n","    res = \" \".join(res).replace(\"<bos>\", \"\")\n","    return res\n","\n","\n","\n","class BaseTranslatedLightningModule(pl.LightningModule):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.loss_function = torch.nn.CrossEntropyLoss(\n","            ignore_index=cfg.data.vocab.special_symbol2index[\"<pad>\"]\n","        )\n","\n","    def configure_optimizers(self):\n","        self._optimizers, self._scheduler = configure_optimizers_from_cfg(\n","            self.cfg, self\n","        )\n","        return self._optimizers, self._scheduler\n","\n","    @abstractmethod\n","    def forward(self, src, tgt, teacher_forcing_ratio: float):\n","        raise NotImplementedError()\n","\n","    def _forward(self, src, tgt, mode: str, teacher_forcing_ratio: float = 0.5):\n","        # teacher forcing:\n","        # seq2seq 에서 많이 쓰인다\n","        # src -> tgt autoregressive 학습하면, 맨 최소는 학습을 빠르게 하지만, 미래부분 학습은 기다리기 너무 힘들다\n","        # 랜덤으로 미래 정보도 조금 둬서 뒤에 있는 정보도 학습이 가능하게함\n","        # 0.5 확룰로 teacher_forcing을 하겠다\n","\n","        assert mode in [\"train\", \"val\", \"test\"]\n","\n","        # get predictions\n","        # teacher_forcing 용 input -->\n","        tgt_inputs = tgt[:-1, :] # delete ends for teacher forcing inputs\n","        outputs = self(src, tgt_inputs, teacher_forcing_ratio=teacher_forcing_ratio)\n","        tgt_outputs = tgt[1:, :] # delete start tokens\n","\n","        loss = self.loss_function(\n","            outputs.reshape(-1, outputs.shape[-1]), # [[batch X Seq_size], other_output_shape]\n","            tgt_outputs.reshape(-1),\n","        )\n","\n","        logs_detail = {\n","            f\"{mode}_src\": src,\n","            f\"{mode}_tgt\": tgt,\n","            f\"{mode}_results\": outputs,\n","        }\n","\n","        if mode in [\"val\", \"test\"]:\n","            _, tgt_results = torch.max(outputs, dim=2)\n","\n","            src_texts = []\n","            tgt_texts = []\n","            res_texts = []\n","\n","            # convert [L X B X others] --> [b X L X others]\n","            for src_i in torch.transpose(src, 0, 1).detach().cpu().numpy().tolist():\n","                res = vocab_transform[self.cfg.data.src_lang].lookup_tokens(src_i)\n","                src_text.append(_text_postprocessing(res))\n","\n","            for tgt_i in torch.transpose(tgt, 0, 1).detach().cpu().numpy().tolist():\n","                res = vocab_transform[self.cfg.data.tgt_lang].lookup_tokens(tgt_i)\n","                tgt_text.append(_text_postprocessing(res))\n","\n","            for tgt_res_i in torch.transpose(tgt_results, 0, 1).detach().cpu().numpy().tolist():\n","                res = vocab_transform[self.cfg.data.tgt_lang].lookup_tokens(tgt_res_i)\n","                res_text.append(_text_postprocessing(res))\n","\n","            text_result_summary = {\n","                f\"{mode}_src_text\": src_texts,\n","                f\"{mode}_tgt_text\": tgt_texts,\n","                f\"{mode}_results_text\": res_texts,\n","            }\n","            print(f\"{self.global_step} step: \\n src_text: {src_texts[0]}, \\n tgt_text: {tgt_texts[0]}, \\n result_text: {res_texts[0]}\")\n","            logs_detail.update(text_result_summary)\n","\n","        return {f\"{mode}_loss\":loss}, logs_detail\n","\n","    def training_step(self, batch, batch_idx):\n","        src, tgt = batch[0], batch[1]\n","        logs, _ = self._forward(src, tgt, \"train\", self.cfg.model.teacher_forcing_ratio)\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"train_loss\"]\n","        return logs\n","\n","    def validation_step(self, batch, batch_idx):\n","        src, tgt = batch[0], batch[1]\n","        logs, _ = self._forward(src, tgt, \"val\", 0.0)\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"val_loss\"]\n","        logs.update(logs_detail)\n","        return logs\n","\n","    def test_step(self, batch, batch_idx):\n","        src, tgt = batch[0], batch[1]\n","        logs, _ = self._forward(src, tgt, \"test\", 0.0)\n","        self.log_dict(logs)\n","        logs[\"loss\"] = logs[\"test_loss\"]\n","        logs.update(logs_detail)\n","        return logs"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_AT5VFyP6sq","executionInfo":{"status":"ok","timestamp":1637673113148,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# untils for initializations\n","def init_weights(model: Union[nn.Module, pl.LightningModule]):\n","    for name, param in model.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzgYXgyhb2Ar","executionInfo":{"status":"ok","timestamp":1637673113148,"user_tz":-540,"elapsed":6,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# model definition\n","\n","# 1. encoder\n","class LSTMEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        input_dim: int,\n","        embed_dim: int,\n","        hidden_dim: int,\n","        n_layers: int,\n","        dropout: float\n","    ):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.n_layers =n_layers\n","        self.embedding = nn.Embedding(input_dim, embed_dim)\n","        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # initialization of weights\n","        self.apply(init_weights)\n","\n","    def forward(self, src):\n","        # src = [seq_len, batch_size]\n","        embedded = self.dropout(self.embedding(src)) # [seq_len, batch_size, emb_dim]\n","\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","\n","        # outputs = [src_len, batch_size, hidden_dim * n direction]\n","        # hidden, cell = [n layers * n directions, batch_size, hidden_dim]\n","\n","        # outputs will be used from top hidden layers\n","        return hidden, cell\n","\n","# 2. decoder\n","class LSTMDecoder(nn.Module):\n","    def __init__(\n","        self,\n","        output_dim: int,\n","        embed_dim: int,\n","        hidden_dim: int,\n","        n_layers: int,\n","        dropout: float\n","    ):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_layers =n_layers\n","\n","        self.output_dim = output_dim\n","        self.embedding = nn.Embedding(output_dim, embed_dim)\n","        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout)\n","        self.fc_out = nn.Linear(hidden_dim , output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, cell):\n","        # input: [batch size X ...] <- start token\n","\n","        # outputs = [src_len, batch_size, hidden_dim * n direction]\n","        # hidden, cell = [n layers * n directions, batch_size, hidden_dim]\n","\n","        input = input.unsqueeze(0) # <- [1, batch_size]\n","        embedded = self.dropout(self.embedding(input))\n","\n","        # embedding = [1, batch_size, embed_dim]\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","\n","        # output = [1, batch_size, hidden_size]\n","        # hidden, cell = [n layers * 1 directions, batch_size, hidden_dim]\n","\n","        prediction = self.fc_out(output.squeeze(0)) # [batch_size, output_size]\n","\n","        return prediction, hidden, cell\n","\n"," # 3. Seq2Seq(cfg) <-- encoder + decoder\n","class LSTMSeq2Seq(BaseTranslatedLightningModule):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__(cfg)\n","\n","        self.encoder = LSTMEncoder(**cfg.model.enc)\n","        self.decoder = LSTMDecoder(**cfg.model.dec)\n","\n","        assert self.encoder.hidden_dim == self.decoder.hidden_dim\n","        assert self.encoder.n_layers == self.decoder.n_layers\n","         \n","        # paramerters 들 init.\n","        self.apply(init_weights)\n","\n","    def forward(self, src, tgt, teacher_forcing_ratio: float = 0.5):\n","\n","        # src, tgt = [seq_len(can be different), batch_size]\n","        # for val, test teacher forcing should be 0.0\n","\n","        batch_size = tgt.shape[1]\n","        tgt_len = tgt.shape[0]\n","        tgt_vocab_size = self.decoder.output_dim\n","\n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(tgt_len, batch_size, tgt_vocab_size).to(self.device)\n","\n","        hidden, cell = self.encoder(src)\n","\n","        # start_token_input (<sos> tokens)\n","        input = tgt[0, :]\n","\n","        for t in range(1, tgt_len):\n","            \n","            # get one cell's output\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","\n","            # set to all outpus results\n","            outputs[t] = output\n","\n","            # decide whether going to us teacher forcing or not.\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            top1 = output.argmax()\n","\n","            input = tgt[t] if teacher_force else top1\n","\n","        return outputs"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6dMxy6rzJza","executionInfo":{"status":"ok","timestamp":1637673113639,"user_tz":-540,"elapsed":11,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["# Concat; Addictive Attention 기반의 모델 새로 정의\n","# encoder, decoder rnn이 다를 수 있다\n","\n","class BidirectionalGRUEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        input_dim: int,\n","        embed_dim: int,\n","        enc_hidden_dim: int,\n","        dec_hidden_dim: int,\n","        n_layers: int,\n","        dropout: float\n","    ):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        self.n_layers =n_layers\n","\n","        self.embedding = nn.Embedding(input_dim, embed_dim)\n","        self.rnn = nn.GRU(embed_dim, enc_hidden_dim, n_layers, bidirectional=True, dropout=dropout)\n","        self.fc = nn.Linear(enc_hidden_dim * 2, dec_hidden_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # initialization of weights\n","        self.apply(init_weights)\n","\n","    def forward(self, src):\n","\n","        # src = [seq_len, batch_size]\n","        embedded = self.dropout(self.embedding(src)) # [seq_len, batch_size, emb_dim]\n","\n","        outputs, hidden = self.rnn(embedded)\n","        # outputs = [src_len, batch_size, hidden_dim * n direction]\n","        # hidden = [n layers * n directions, batch_size, hidden_dim]\n","\n","        # hidden -> [forward_1, backward_1, forward_2, backward_2, ...]\n","        # 우리가 필요한건 맨 마지막 layer의 forward backward 두개 concat 한개 필요\n","\n","        # encoder RNNs fed through a linear layer to connect decoder.\n","        hidden = torch.tanh(self.fc(\n","            torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","        ))\n","\n","        return outputs, hidden\n","\n","class ConcatAttention(nn.Module):\n","    def __init__(self, enc_hidden_dim: int, dec_hidden_dim: int):\n","        super().__init__()\n","\n","        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)\n","        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n","\n","    def forward(self, hidden, encoder_outputs):\n","\n","        # hidden = [batch_size, dec_hidden_dim] => from decoder. (query)\n","        # encdoer_outputs = [src_len, batch_szie, enc_hidden_dim * 2] (key, value)\n","\n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","\n","        # repeat decoder hidden state src_len time ...\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        # hidden: [batch_size, src_len, dec_hidden_dim]\n","        # encoder_outputs = [batch_size, src_len, enc_hidden_dim *2]\n","\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n","\n","        # energy = [batch_size, src_len, dec_hidden_dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","\n","        # attention = [batch_size, src_len]\n","\n","        return F.softmax(attention, dim=1)\n","\n","class AttentionalRNNDecoder(nn.Module):\n","    def __init__(\n","        self,\n","        output_dim: int,\n","        embed_dim: int,\n","        enc_hidden_dim: int,\n","        dec_hidden_dim: int,\n","        n_layers: int,\n","        dropout: float,\n","        attention: nn.Module\n","    ):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.attention = attention\n","\n","        self.embedding = nn.Embedding(output_dim, embed_dim)\n","\n","        self.rnn = nn.GRU((enc_hidden_dim * 2) + embed_dim, dec_hidden_dim, n_layers, dropout=dropout)\n","\n","        self.fc_out = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim + embed_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, input, hidden, encoder_outputs):\n","\n","        # input [batch size] # start_token\n","        # hidden [batch_size, dec_hidden_dim]\n","        # encoder_outputs [src_len, batch_size, enc_hidden_dim*2]\n","\n","        input = input.unsqueeze(0) # input = [1, batch_size]\n","\n","        embedded = self.dropout(self.embedding(input)) # [1, batch_size, embed_dim]\n","\n","        a = self.attention(hidden, encoder_outputs) # [batch_size, src_len]\n","        a = a.unsqueeze(1) # [batch_size, 1, src_len]\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2) # [batch_size, src_len, enc_hidden_dim*2]\n","        weighted = torch.bmm(a, encoder_outputs) # [batch_size, 1, enc_hidden_dim*2]\n","        weighted = weighted.permute(1, 0, 2) # [1, batch_size, enc_hidden_dim*2]\n","\n","        rnn_input = torch.cat((embedded, weighted), dim=2) # [1, batch_size, (enc_hidden_dim* + embed_dim)]\n","\n","        # hidden unsqueeze : [1, batch_size, dec_hidden_dim]\n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0)) \n","        # output = [seq_len, batch_size, dec_hidden_dim * n driections] => [1, batch_size, dec_hidden_size]\n","        # hidden = [n layers * n_directions, batch_size, dec_hidden_dim] => [1, batch_size, dec_hidden_size]\n","\n","\n","        if not (output == hidden).all():\n","            raise AssertionError()\n","\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1)) #[batch_size, ouput_dim]\n","\n","        return prediction, hidden.squeeze(0)\n","\n","class AttentionBaseSeq2Seq(BaseTranslatedLightningModule):\n","    def __init__(self, cfg: DictConfig):\n","        super().__init__(cfg)\n","\n","        self.encoder = BidirectionalGRUEncoder(**cfg.model.enc)\n","        self.attention = ConcatAttention(**cfg.model.attention)\n","        self.decoder = AttentionalRNNDecoder(\n","            attention=self.attention, **cfg.model.dec\n","        )\n","\n","    def forward(self, src, tgt, teacher_forcing_ratio: float = 0.5):\n","\n","        # src, tgt = [seq_len(can be different), batch_size]\n","        # for val, test teacher forcing should be 0.0\n","\n","        batch_size = tgt.shape[1]\n","        tgt_len = tgt.shape[0]\n","        tgt_vocab_size = self.decoder.output_dim\n","\n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(tgt_len, batch_size, tgt_vocab_size).to(self.device)\n","\n","        encoder_outputs, hidden = self.encoder(src)\n","\n","        # start_token_input (<sos> tokens)\n","        input = tgt[0, :]\n","\n","        for t in range(1, tgt_len):\n","            \n","            # get one cell's output\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","\n","            # set to all outpus results\n","            outputs[t] = output\n","\n","            # decide whether going to us teacher forcing or not.\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            top1 = output.argmax()\n","\n","            input = tgt[t] if teacher_force else top1\n","\n","        return outputs"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSCGZBbVhOI8","executionInfo":{"status":"ok","timestamp":1637673122747,"user_tz":-540,"elapsed":9117,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"source":["data_spacy_de_en_cfg = {\n","    \"name\": \"spacy_de_en\",\n","    \"data_root\": os.path.join(os.getcwd(), \"data\"),\n","    'tokenizer': \"spacy\",\n","    \"src_lang\": \"de\",\n","    \"tgt_lang\": \"en\",\n","    \"src_index\": 0,\n","    \"tgt_index\": 1,\n","    \"vocab\": {\n","        \"special_symbol2index\": {\n","            \"<unk>\": 0,\n","            \"<pad>\": 1,\n","            \"<bos>\": 2,\n","            \"<eos>\": 3,\n","            \n","        },\n","        \"special_first\": True,\n","        \"min_freq\": 2\n","    }\n","}\n","\n","data_cfg = OmegaConf.create(data_spacy_de_en_cfg)\n","\n","# get_dataset\n","train_data,vaild_data, test_data = Multi30k(data_cfg.data_root)\n","\n","token_transform = get_token_transform(data_cfg)\n","vocab_transform = get_vocab_transform(data_cfg)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-BeLE3hiVzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673123118,"user_tz":-540,"elapsed":375,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"8f180420-a9a1-4922-b3c4-9f47fdbb7716"},"source":["# model configs\n","\n","model_translate_lstm_seq2seq_cfg = {\n","    \"name\": \"LSTMSeq2Seq\",\n","    'enc': {\n","        \"input_dim\": len(vocab_transform[data_cfg.src_lang]),\n","        \"embed_dim\": 256,\n","        \"hidden_dim\": 256,\n","        \"n_layers\": 2,\n","        \"dropout\": 0.5,\n","    },\n","    \"dec\": {\n","        \"output_dim\": len(vocab_transform[data_cfg.tgt_lang]),\n","        \"embed_dim\": 256,\n","        \"hidden_dim\": 256,\n","        \"n_layers\": 2,\n","        \"dropout\": 0.5,\n","    },\n","    \"teacher_forcing_ratio\": 0.5,\n","}\n","\n","model_translate_attention_based_seq2seq_cfg = {\n","    \"name\": \"AttentionBasedSeq2Seq\",\n","    'enc': {\n","        \"input_dim\": len(vocab_transform[data_cfg.src_lang]),\n","        \"embed_dim\": 256,\n","        \"enc_hidden_dim\": 512,\n","        \"dec_hidden_dim\": 512,\n","        \"n_layers\": 1,\n","        \"dropout\": 0.5,\n","    },\n","    \"dec\": {\n","        \"output_dim\": len(vocab_transform[data_cfg.tgt_lang]),\n","        \"embed_dim\": 256,\n","        \"enc_hidden_dim\": 512,\n","        \"dec_hidden_dim\": 512,\n","        \"n_layers\": 1,\n","        \"dropout\": 0.5,\n","    },\n","    \"attention\":{\n","        \"enc_hidden_dim\": 512,\n","        \"dec_hidden_dim\": 512,\n","    },\n","    \"teacher_forcing_ratio\": 0.5,\n","}\n","\n","# opt_config\n","opt_cfg = {\n","    \"optimizers\": [\n","        {\n","            \"name\": \"RAdam\",\n","            \"kwargs\": {\n","                \"lr\": 1e-3,\n","            }\n","        }\n","    ],\n","    \"lr_schedulers\": [\n","        {\n","        \"name\": None,\n","        \"kwargs\": {\n","            \"warmup_end_steps\": 1000\n","        }\n","    }\n","    ]\n","}\n","\n","_merged_cfg_presets = {\n","    \"LSTM_seq2seq_de_en_translate\": {\n","        \"opt\": opt_cfg,\n","        \"data\": data_spacy_de_en_cfg,\n","        \"model\": model_translate_lstm_seq2seq_cfg\n","    },\n","    \"attention_based_seq2seq_de_en_translate\": {\n","        \"opt\": opt_cfg,\n","        \"data\": data_spacy_de_en_cfg,\n","        \"model\": model_translate_attention_based_seq2seq_cfg\n","    }\n","}\n","\n","# clear config hydra instance first\n","hydra.core.global_hydra.GlobalHydra.instance().clear()\n","\n","# register preset configs\n","register_config(_merged_cfg_presets)\n","\n","# initialization & compose configs\n","hydra.initialize(config_path=None)\n","cfg = hydra.compose('attention_based_seq2seq_de_en_translate')\n","\n","# override some cfg\n","run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n","\n","project_root_dir = os.path.join(\n","    drive_project_root, \"runs\", \"de_en_translate_tutorials\"\n",")\n","save_dir = os.path.join(project_root_dir, run_name)\n","run_root_dir = os.path.join(project_root_dir, run_name)\n","\n","# train configs\n","train_cfg = {\n","    \"train_batch_size\": 128,\n","    \"val_batch_size\": 32,\n","    \"test_batch_size\": 32,\n","    \"train_val_split\": [0.9, 0.1],\n","    \"run_root_dir\": run_root_dir,\n","    \"trainer_kwargs\": {\n","        \"accelerator\": \"dp\",\n","        \"gpus\": \"0\",\n","        \"max_epochs\": 50,\n","        \"val_check_interval\": 1.0,\n","        \"log_every_n_steps\": 100,\n","        \"flush_logs_every_n_steps\": 100,\n","    }\n","}\n","\n","# logger configs\n","log_cfg = {\n","    \"loggers\": {\n","        \"WandbLogger\": {\n","            \"project\": \"fastcampus_de_en_translate_tutorials\",\n","            'name': run_name,\n","            \"tags\": [\"fastcampus_de_en_translate_tutorials\"],\n","            \"save_dir\": run_root_dir,\n","        },\n","        \"TensorBoardLogger\": {\n","            \"save_dir\": project_root_dir,\n","            \"name\": run_name,\n","        }\n","    },\n","    \"callbacks\": {\n","        \"ModelCheckpoint\": {\n","            \"save_top_k\": 3,\n","            \"monitor\": \"val_loss\",\n","            \"mode\": \"min\",\n","            \"verbose\": True,\n","            \"dirpath\": os.path.join(run_root_dir, \"weights\"),\n","            \"filename\": \"{epoch}-{val_loss:.3f}-{val_acc:.3f}\"\n","        },\n","        \"EarlyStopping\": {\n","            \"monitor\": \"val_loss\",\n","            \"mode\": \"min\",\n","            \"patience\": 3,\n","            \"verbose\": True\n","        }\n","    }\n","}\n","\n","OmegaConf.set_struct(cfg, False)\n","cfg.train = train_cfg\n","cfg.log = log_cfg\n","# lock config\n","OmegaConf.set_struct(cfg, True)\n","print(OmegaConf.to_yaml(cfg))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["opt:\n","  optimizers:\n","  - name: RAdam\n","    kwargs:\n","      lr: 0.001\n","  lr_schedulers:\n","  - name: null\n","    kwargs:\n","      warmup_end_steps: 1000\n","data:\n","  name: spacy_de_en\n","  data_root: /content/data\n","  tokenizer: spacy\n","  src_lang: de\n","  tgt_lang: en\n","  src_index: 0\n","  tgt_index: 1\n","  vocab:\n","    special_symbol2index:\n","      <unk>: 0\n","      <pad>: 1\n","      <bos>: 2\n","      <eos>: 3\n","    special_first: true\n","    min_freq: 2\n","model:\n","  name: AttentionBasedSeq2Seq\n","  enc:\n","    input_dim: 8015\n","    embed_dim: 256\n","    enc_hidden_dim: 512\n","    dec_hidden_dim: 512\n","    n_layers: 1\n","    dropout: 0.5\n","  dec:\n","    output_dim: 6192\n","    embed_dim: 256\n","    enc_hidden_dim: 512\n","    dec_hidden_dim: 512\n","    n_layers: 1\n","    dropout: 0.5\n","  attention:\n","    enc_hidden_dim: 512\n","    dec_hidden_dim: 512\n","  teacher_forcing_ratio: 0.5\n","train:\n","  train_batch_size: 128\n","  val_batch_size: 32\n","  test_batch_size: 32\n","  train_val_split:\n","  - 0.9\n","  - 0.1\n","  run_root_dir: /content/drive/MyDrive/#fastcampus/runs/de_en_translate_tutorials/2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en\n","  trainer_kwargs:\n","    accelerator: dp\n","    gpus: '0'\n","    max_epochs: 50\n","    val_check_interval: 1.0\n","    log_every_n_steps: 100\n","    flush_logs_every_n_steps: 100\n","log:\n","  loggers:\n","    WandbLogger:\n","      project: fastcampus_de_en_translate_tutorials\n","      name: 2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en\n","      tags:\n","      - fastcampus_de_en_translate_tutorials\n","      save_dir: /content/drive/MyDrive/#fastcampus/runs/de_en_translate_tutorials/2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en\n","    TensorBoardLogger:\n","      save_dir: /content/drive/MyDrive/#fastcampus/runs/de_en_translate_tutorials\n","      name: 2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en\n","  callbacks:\n","    ModelCheckpoint:\n","      save_top_k: 3\n","      monitor: val_loss\n","      mode: min\n","      verbose: true\n","      dirpath: /content/drive/MyDrive/#fastcampus/runs/de_en_translate_tutorials/2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en/weights\n","      filename: '{epoch}-{val_loss:.3f}-{val_acc:.3f}'\n","    EarlyStopping:\n","      monitor: val_loss\n","      mode: min\n","      patience: 3\n","      verbose: true\n","\n"]}]},{"cell_type":"code","metadata":{"id":"1r501wRqkxVp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673124287,"user_tz":-540,"elapsed":1172,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"f8421b90-2e79-4779-f1b5-436ca70490af"},"source":["# dataloader def\n","train_dataloader = get_multi30k_dataloader(\n","    \"train\",\n","    (data_cfg.src_lang, data_cfg.tgt_lang),\n","    cfg.train.train_batch_size,\n","    collate_fn=get_collate_fn(cfg)\n",")\n","val_dataloader = get_multi30k_dataloader(\n","    \"valid\",\n","    (data_cfg.src_lang, data_cfg.tgt_lang),\n","    cfg.train.val_batch_size,\n","    collate_fn=get_collate_fn(cfg)\n",")\n","test_dataloader = get_multi30k_dataloader(\n","    \"test\",\n","    (data_cfg.src_lang, data_cfg.tgt_lang),\n","    cfg.train.test_batch_size,\n","    collate_fn=get_collate_fn(cfg)\n",")"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 218kB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"4a1HSw9cnNSF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673124775,"user_tz":-540,"elapsed":247,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"36df1b2c-2035-4df8-da8c-0e718df15cb1"},"source":["# pl trainer def & get model\n","\n","def get_pl_model(cfg: DictConfig, checkpoint_path: Optional[str] = None):\n","\n","    if cfg.model.name == \"LSTMSeq2Seq\":\n","        model = LSTMSeq2Seq(cfg)\n","    elif cfg.model.name == \"AttentionBasedSeq2Seq\":\n","        model = AttentionBaseSeq2Seq(cfg)\n","    else:\n","        raise NotImplementedError(\"Not implemented model\")\n","\n","    if checkpoint_path is not None:\n","        model = model.load_from_checkpoint(cfg, checkpoint_path=checkpoint_path)\n","    return model\n","\n","\n","model = None\n","model = get_pl_model(cfg)\n","print(model)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"output_type":"stream","name":"stdout","text":["AttentionBaseSeq2Seq(\n","  (loss_function): CrossEntropyLoss()\n","  (encoder): BidirectionalGRUEncoder(\n","    (embedding): Embedding(8015, 256)\n","    (rnn): GRU(256, 512, dropout=0.5, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (attention): ConcatAttention(\n","    (attn): Linear(in_features=1536, out_features=512, bias=True)\n","    (v): Linear(in_features=512, out_features=1, bias=False)\n","  )\n","  (decoder): AttentionalRNNDecoder(\n","    (attention): ConcatAttention(\n","      (attn): Linear(in_features=1536, out_features=512, bias=True)\n","      (v): Linear(in_features=512, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(6192, 256)\n","    (rnn): GRU(1280, 512, dropout=0.5)\n","    (fc_out): Linear(in_features=1792, out_features=6192, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"yPgBa1JpoqDo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637673125096,"user_tz":-540,"elapsed":326,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"ec8c326e-60ea-496c-c6ab-083e633f8335"},"source":["# pytorch lightning trainer def\n","logger = get_loggers(cfg)\n","callbacks = get_callbacks(cfg)\n","\n","trainer = pl.Trainer(\n","    callbacks=callbacks,\n","    logger=logger,\n","    default_root_dir = cfg.train.run_root_dir,\n","    num_sanity_val_steps=2,\n","    **cfg.train.trainer_kwargs\n",")"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/device_parser.py:131: LightningDeprecationWarning: Parsing of the Trainer argument gpus='0' (string) will change in the future. In the current version of Lightning, this will select CUDA device with index 0, but from v1.5 it will select gpus [] (same as gpus=0 (int)).\n","  f\"Parsing of the Trainer argument gpus='{s}' (string) will change in the future.\"\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n"]}]},{"cell_type":"code","metadata":{"id":"I1ZQ8Sdrsjm8","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c5c5bd577ee244ce92b8286e3a4ae12c","eb73c14b912b4d84be558a54dc3794a8","d6a1e9c1fad34303a2c5e4c28ac3c80f","463477177d3b4d4ebba7ae1d26f79b05","9b7717f944eb41e6b5b190b27449721a","d0bde53140324cbc8b5943843a6cc29e","0af4daab22f240818d294cde9f19b4ce","ffed1d1b3d0d4d33b68ae6974cb5b410","cda42c7ecbbf4aca9abef100f965e06c","0582e8b9848f41b6b8488486439ed637","c9f627137eaf47c1ab7b6bc4460e98f5"]},"executionInfo":{"status":"error","timestamp":1637673142316,"user_tz":-540,"elapsed":17227,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"e5606fff-62a3-4db3-fe48-35d22f0efeff"},"source":["trainer.fit(model, train_dataloader, test_dataloader)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.11.1<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/lemma17/fastcampus_de_en_translate_tutorials\" target=\"_blank\">https://wandb.ai/lemma17/fastcampus_de_en_translate_tutorials</a><br/>\n","                Run page: <a href=\"https://wandb.ai/lemma17/fastcampus_de_en_translate_tutorials/runs/2tr2ayjk\" target=\"_blank\">https://wandb.ai/lemma17/fastcampus_de_en_translate_tutorials/runs/2tr2ayjk</a><br/>\n","                Run data is saved locally in <code>/content/drive/MyDrive/#fastcampus/runs/de_en_translate_tutorials/2021-11-23T13:12:01-AttentionBasedSeq2Seq-spacy_de_en/wandb/run-20211123_131212-2tr2ayjk</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","  | Name          | Type                    | Params\n","----------------------------------------------------------\n","0 | loss_function | CrossEntropyLoss        | 0     \n","1 | encoder       | BidirectionalGRUEncoder | 4.9 M \n","2 | attention     | ConcatAttention         | 787 K \n","3 | decoder       | AttentionalRNNDecoder   | 16.2 M\n","----------------------------------------------------------\n","21.2 M    Trainable params\n","0         Non-trainable params\n","21.2 M    Total params\n","84.690    Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5c5bd577ee244ce92b8286e3a4ae12c","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-70722073b161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    458\u001b[0m         )\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, on_epoch)\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/dp.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/overrides/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_replica_device_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# forward call will redirect to training_step, validation_step, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0moutput_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/overrides/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanity_checking\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-803bb1bd99fa>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-803bb1bd99fa>\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, src, tgt, mode, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# teacher_forcing 용 input -->\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtgt_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# delete ends for teacher forcing inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtgt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# delete start tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-228a80152e5b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# get one cell's output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# set to all outpus results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-228a80152e5b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [1, batch_size, enc_hidden_dim*2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [1, batch_size, (enc_hidden_dim* + embed_dim)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# hidden unsqueeze : [1, batch_size, dec_hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"]}]}]}