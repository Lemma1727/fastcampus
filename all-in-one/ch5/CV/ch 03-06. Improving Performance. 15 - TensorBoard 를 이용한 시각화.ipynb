{"cells":[{"cell_type":"markdown","metadata":{"id":"_e1aODO1FBhc"},"source":["# TensorBoard visualization"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"7GmR3rWjAEgo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642057392771,"user_tz":-540,"elapsed":22524,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"45f495f8-770d-4c57-e116-6111d93d96ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install albumentations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-PCBgd8Ok7S","executionInfo":{"status":"ok","timestamp":1642057403343,"user_tz":-540,"elapsed":7960,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"bbaa6aff-0bfe-441f-8ba0-a15e9f78ab6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n","Collecting imgaug<0.2.7,>=0.2.5\n","  Downloading imgaug-0.2.6.tar.gz (631 kB)\n","\u001b[K     |████████████████████████████████| 631 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.2.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.6)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654017 sha256=dc899033666e5e9ffe646bc698fc170269c5048aaa6e30ce1a939a08d4f938b2\n","  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gm1lcZolFBhr"},"outputs":[],"source":["import os\n","import math\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '4'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5IYuvetFBhw"},"outputs":[],"source":["import tensorflow.keras.losses as losses\n","\n","def iou(y_true, y_pred):\n","    smooth = 0.\n","    \n","    # Flatten\n","    y_true = tf.reshape(y_true, [-1])\n","    y_pred = tf.reshape(y_pred, [-1])\n","    \n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n","    \n","    score = intersection / (union + smooth)\n","    return score\n","\n","\n","def dice_coef(y_true, y_pred):\n","    smooth = 0.\n","    \n","    # Flatten\n","    y_true = tf.reshape(y_true, [-1])\n","    y_pred = tf.reshape(y_pred, [-1])\n","    \n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    score = (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","    \n","    return score\n","\n","\n","def dice_loss(y_true, y_pred):\n","    loss = 1 - dice_coef(y_true, y_pred)\n","\n","    return loss\n","\n","\n","def bce_dice_loss(y_true, y_pred):\n","    loss = 1.*losses.binary_crossentropy(y_true, y_pred) + 1.*dice_loss(y_true, y_pred)\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"SfnDxmnVFBh0","executionInfo":{"status":"error","timestamp":1642057411109,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"67bba952-2b76-47a2-904c-0c9fe8662f42"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fce19db4f7bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     shuffle=True)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m valid_generator = DataGenerator(\n","\u001b[0;32m<ipython-input-5-fce19db4f7bf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, csv_path, image_size, fold, mode, shuffle)\u001b[0m\n\u001b[1;32m     62\u001b[0m         ]\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-fce19db4f7bf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mrotate_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 ),\n\u001b[0;32m---> 17\u001b[0;31m                 A.CoarseDropout(\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mmax_holes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'CoarseDropout'"]}],"source":["from tensorflow import keras\n","import albumentations as A\n","import cv2\n","\n","class Augmentation:\n","    def __init__(self, size, mode='train'):\n","        if mode == 'train':\n","            # Declare an augmentation pipeline\n","            self.transform = A.Compose([\n","                A.HorizontalFlip(p=0.5),\n","                A.ShiftScaleRotate(\n","                    p=0.5,\n","                    shift_limit=0.05,\n","                    scale_limit=0.05,\n","                    rotate_limit=15,\n","                ),\n","                A.CoarseDropout(\n","                    p=0.5,\n","                    max_holes=8,\n","                    max_height=int(0.1 * size),\n","                    max_width=int(0.1 * size)\n","                ),\n","                A.RandomBrightnessContrast(p=0.2),\n","            ])\n","    def __call__(self, **kwargs):\n","        if self.transform:\n","            augmented = self.transform(**kwargs)\n","            img = augmented['image']\n","            mask = augmented['mask']\n","            return img, mask\n","        \n","class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, csv_path, image_size,\n","                 fold, mode='train', shuffle=True):\n","        self.fold = fold\n","        self.shuffle = shuffle\n","        self.mode = mode\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        \n","        self.df = pd.read_csv(csv_path)\n","        if self.mode == 'train':    \n","            self.df = self.df[self.df['fold'] != self.fold]\n","        elif self.mode == 'val':\n","            self.df = self.df[self.df['fold'] == self.fold]\n","        \n","        #### Remove invalid files\n","        #### https://github.com/tensorflow/models/issues/3134\n","        invalid_filenames = [\n","            'Egyptian_Mau_14',\n","            'Egyptian_Mau_139',\n","            'Egyptian_Mau_145',\n","            'Egyptian_Mau_156',\n","            'Egyptian_Mau_167',\n","            'Egyptian_Mau_177',\n","            'Egyptian_Mau_186',\n","            'Egyptian_Mau_191',\n","            'Abyssinian_5',\n","            'Abyssinian_34',\n","            'chihuahua_121',\n","            'beagle_116'\n","        ]\n","        self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n","        self.transform = Augmentation(image_size, mode)\n","        \n","        self.on_epoch_end()\n","            \n","    def __len__(self):\n","        return math.ceil(len(self.df) / self.batch_size)\n","    \n","    def __getitem__(self, idx):\n","        strt = idx * self.batch_size\n","        fin = (idx + 1) * self.batch_size\n","        data = self.df.iloc[strt:fin]\n","        \n","        batch_x, batch_y = self.get_data(data)\n","\n","        return np.array(batch_x), np.array(batch_y)\n","        \n","    def get_data(self, data):\n","        batch_x = []\n","        batch_y = []\n","    \n","        for _, r in data.iterrows():\n","            file_name = r['file_name']\n","\n","            image = cv2.imread(f'/content/drive/MyDrive/data/images/{file_name}.jpg')\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            image = cv2.resize(image, (self.image_size, self.image_size))\n","            \n","            mask = cv2.imread(f'/content/drive/MyDrive/data/annotations/trimaps/{file_name}.png',\n","                              cv2.IMREAD_GRAYSCALE)\n","            mask = cv2.resize(mask, (self.image_size, self.image_size))\n","            mask[mask != 1] = 0\n","            \n","            if self.mode == 'train':\n","                #image = image.astype('uint8')\n","                image, mask = self.transform(image=image, mask=mask)\n","                \n","            image = image.astype('float32')\n","            image = image / 255.\n","            mask = mask.astype('float32')\n","\n","            batch_x.append(image)\n","            batch_y.append(mask)\n","        \n","        return batch_x, batch_y\n","        \n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.df = self.df.sample(frac=1).reset_index(drop=True)\n","            \n","csv_path = '/content/drive/MyDrive/data/kfolds.csv'\n","train_generator = DataGenerator(\n","    fold=1,\n","    mode='train',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=128,\n","    shuffle=True)\n","\n","valid_generator = DataGenerator(\n","    fold=1,\n","    mode='val',\n","    csv_path=csv_path,\n","    batch_size=128,\n","    image_size=128,\n","    shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1cbI4yWFBh7"},"outputs":[],"source":["# https://github.com/karolzak/keras-unet\n","from keras_unet.models import custom_unet\n","\n","model = custom_unet(\n","    input_shape=(128, 128, 3),\n","    use_batch_norm=True,\n","    upsample_mode='deconv',\n","    dropout_type='spatial',\n","    use_attention=True,\n","    num_classes=1,\n","    filters=64,\n","    dropout=0.2,\n","    num_layers=4,\n","    output_activation='sigmoid')\n","\n","model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[iou])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RztS4M1iFBh_"},"outputs":[],"source":["def plot_to_image(figure):\n","    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n","    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n","    # Save the plot to a PNG in memory.\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='png')\n","    # Closing the figure prevents it from being displayed directly inside\n","    # the notebook.\n","    plt.close(figure)\n","    buf.seek(0)\n","    # Convert PNG buffer to TF image\n","    image = tf.image.decode_png(buf.getvalue(), channels=4)\n","    # Add the batch dimension\n","    image = tf.expand_dims(image, 0)\n","    return image\n","\n","\n","def image_grid(img, mask, preds):  \n","    figure = plt.figure(figsize=(10, 10))\n","    for i in range(3):\n","        plt.subplot(3, 3, 3*i + 1)\n","        plt.imshow(img[i])\n","        plt.axis('off')\n","        plt.title('img')\n","        \n","        plt.subplot(3, 3, 3*i + 2)\n","        plt.imshow(mask[i], cmap='gray')\n","        plt.axis('off')\n","        plt.title('gt')\n","        \n","        plt.subplot(3, 3, 3*i + 3)\n","        plt.imshow(preds[i, ..., 0], cmap='gray')\n","        plt.axis('off')\n","        plt.title('pred')\n","    return figure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOB2BvRzFBiB"},"outputs":[],"source":["from tensorflow.keras.callbacks import Callback\n","\n","class TrainHistory(Callback):\n","    def __init__(self, data=None, log_dir='weights'):\n","        self.img, self.mask = data\n","        self.writer = tf.summary.create_file_writer(log_dir)\n","    \n","    def on_epoch_end(self, epoch, logs=None):\n","        preds = self.model.predict(self.img)\n","        \n","        figure = image_grid(self.img, self.mask, pred)\n","        with self.writer.as_default():\n","            tf.summary.image('plot', \n","                plot_to_image(figure), epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTCsf5hCFBiC"},"outputs":[],"source":["from tensorflow.keras.callbacks import TensorBoard\n","\n","callbacks = [\n","    TensorBoard('weights/'),\n","    TrainHistory(\n","        log_dir='weights/',\n","        data=valid_generator[0][:3])\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVMH5JUUFBiG","outputId":"7e5c347c-d2a9-4382-c722-ec1b2cc9c7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"," 1/46 [..............................] - ETA: 0s - loss: 1.5390 - iou: 0.2170WARNING:tensorflow:From /home/fuzzy/anaconda3/envs/fpn-tf2/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n","Instructions for updating:\n","use `tf.profiler.experimental.stop` instead.\n","46/46 [==============================] - 63s 1s/step - loss: 0.9974 - iou: 0.3857 - val_loss: 9.9408 - val_iou: 0.3101\n","Epoch 2/10\n","46/46 [==============================] - 58s 1s/step - loss: 0.7128 - iou: 0.5118 - val_loss: 4.8701 - val_iou: 0.3957\n","Epoch 3/10\n","46/46 [==============================] - 58s 1s/step - loss: 0.5977 - iou: 0.5737 - val_loss: 2.9208 - val_iou: 0.4479\n","Epoch 4/10\n","46/46 [==============================] - 57s 1s/step - loss: 0.5129 - iou: 0.6234 - val_loss: 2.0131 - val_iou: 0.5149\n","Epoch 5/10\n","46/46 [==============================] - 57s 1s/step - loss: 0.4779 - iou: 0.6451 - val_loss: 0.6763 - val_iou: 0.6384\n","Epoch 6/10\n","46/46 [==============================] - 58s 1s/step - loss: 0.4452 - iou: 0.6662 - val_loss: 0.6192 - val_iou: 0.6560\n","Epoch 7/10\n","46/46 [==============================] - 57s 1s/step - loss: 0.4284 - iou: 0.6791 - val_loss: 0.5652 - val_iou: 0.6990\n","Epoch 8/10\n","46/46 [==============================] - 58s 1s/step - loss: 0.4101 - iou: 0.6897 - val_loss: 0.4752 - val_iou: 0.7114\n","Epoch 9/10\n","46/46 [==============================] - 57s 1s/step - loss: 0.3926 - iou: 0.7015 - val_loss: 0.4331 - val_iou: 0.7225\n","Epoch 10/10\n","46/46 [==============================] - 57s 1s/step - loss: 0.3746 - iou: 0.7134 - val_loss: 0.4088 - val_iou: 0.7526\n"]}],"source":["history = model.fit(\n","    train_generator,\n","    validation_data=valid_generator,\n","    epochs=10,\n","    verbose=1,\n","    callbacks=callbacks\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5EcAM9hFBiI","outputId":"fc57c4cf-dc93-4554-dea4-9e56a90e7d03"},"outputs":[{"data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 55785), started 13 days, 23:48:23 ago. (Use '!kill 55785' to kill it.)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-a1db632a712b9ee2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-a1db632a712b9ee2\");\n","          const url = new URL(\"/\", window.location);\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext tensorboard\n","%tensorboard --logdir weights/"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ch 03-06. Improving Performance. 15 - TensorBoard 를 이용한 시각화.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}