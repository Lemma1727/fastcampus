{"cells":[{"cell_type":"markdown","metadata":{"id":"9c7G2VDwrMyi"},"source":["# Data Processing\n","\n","## Intent classification 테스크를 위한 데이터 처리"],"id":"9c7G2VDwrMyi"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvn5YFYzrObS","executionInfo":{"status":"ok","timestamp":1643188704621,"user_tz":-540,"elapsed":9656,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"9ee73d8e-e23c-47f5-bbf6-fc56e941cc69"},"id":"fvn5YFYzrObS","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","!pwd\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25Gxi4SzutOt","executionInfo":{"status":"ok","timestamp":1643189636982,"user_tz":-540,"elapsed":680,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"fc7fb05b-b7cd-4253-fc24-1f664ade7d79"},"id":"25Gxi4SzutOt","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","/content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","/content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","1_1_embedding.ipynb\t 2_1_NLG.ipynb\t\t\t\tchatbot.model\n","1_2_intent_clsf.ipynb\t 2_2_DialogManager.ipynb\t\tchatbot.vocab\n","1_3_entity_recog.ipynb\t 3_1_chit_chat_based_transformer.ipynb\tdata\n","1_4_ood_detection.ipynb  3_2_e2e_dialog.ipynb\t\t\tsrc\n","1_5_NLU_BASE.ipynb\t 4_1_dialog_system.ipynb\n"]}]},{"cell_type":"code","source":["!pip install torch\n","!pip install --upgrade gensim==3.4.0\n","!pip install sentencepiece\n","!pip install pytorch-crf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cY4QRYJpreUb","executionInfo":{"status":"ok","timestamp":1643188787155,"user_tz":-540,"elapsed":39270,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"9894986e-31ab-4e70-d1e7-2f173c91c52d"},"id":"cY4QRYJpreUb","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Collecting gensim==3.4.0\n","  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n","\u001b[K     |████████████████████████████████| 22.2 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.19.5)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.15.0)\n","Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (5.2.1)\n","Building wheels for collected packages: gensim\n","  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gensim: filename=gensim-3.4.0-cp37-cp37m-linux_x86_64.whl size=23316680 sha256=f08b6e8476832af9573b4c01f5f3d1c66e5e5be9920000ebe9c27752a21d921b\n","  Stored in directory: /root/.cache/pip/wheels/de/a4/46/4e18f7d25915b16e0e790a5362e455aba6cadc486994806c05\n","Successfully built gensim\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-3.4.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 18.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting pytorch-crf\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Installing collected packages: pytorch-crf\n","Successfully installed pytorch-crf-0.7.2\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Ao61LhcurMyv","executionInfo":{"status":"ok","timestamp":1643189645554,"user_tz":-540,"elapsed":686,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["import os\n","import sys\n","import json\n","import torch\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from tqdm import trange\n","\n","from gensim.models import Word2Vec\n","from gensim.models.callbacks import CallbackAny2Vec\n","\n","#pip install sentencepiece\n","#pip install pytorch-crf\n","from src.dataset import Preprocessing\n","from src.model import EpochLogger, MakeEmbed\n","\n","class MakeDataset:\n","    def __init__(self):\n","        \n","        self.intent_label_dir = \"./data/dataset/intent_label.json\"\n","        self.intent_data_dir = \"./data/dataset/intent_data.csv\"\n","        \n","        self.intent_label = self.load_intent_label()\n","        self.prep = Preprocessing()\n","    \n","    def load_intent_label(self):\n","        ''' 미리 만들어 둔 예측해야할 intent label 로드'''\n","        f = open(self.intent_label_dir, encoding=\"UTF-8\") \n","        intent_label = json.loads(f.read())\n","        self.intents = list(intent_label.keys())\n","        return intent_label\n","    \n","    def tokenize(self, sentence):\n","        ''' 띄어쓰기 단위로 tokenize 적용'''\n","        return sentence.split()\n","    \n","    def tokenize_dataset(self, dataset):\n","        ''' Dataset에 tokenize 적용'''\n","        token_dataset = []\n","        for data in dataset:\n","            token_dataset.append(self.tokenize(data))\n","        return token_dataset\n","\n","    def make_intent_dataset(self, embed):\n","        ''' intent 분류를 위한 Dataset 생성'''\n","        intent_dataset = pd.read_csv(self.intent_data_dir) # 데이터 로딩\n","\n","        labels = [self.intent_label[label] for label in intent_dataset[\"label\"].to_list()] # label \n","            \n","        intent_querys = self.tokenize_dataset(intent_dataset[\"question\"].tolist()) # 사용자 발화 tokenize\n","        \n","        dataset = list(zip(intent_querys, labels)) # (사용자 발화, intent) 형태로 가공\n","        intent_train_dataset, intent_test_dataset = self.word2idx_dataset(dataset, embed) # word2index\n","        return intent_train_dataset, intent_test_dataset\n","    \n","    def word2idx_dataset(self, dataset ,embed, train_ratio = 0.8):\n","        embed_dataset = []\n","        question_list, label_list = [], []\n","        flag = True\n","        random.shuffle(dataset) #  훈련용과 검증용으로 나눌때 intent 편형이 나타나지 않도록 데이터 셔플\n","        for query, label in dataset :\n","            q_vec = embed.query2idx(query) # 사용자 발화 index화\n","            q_vec = self.prep.pad_idx_sequencing(q_vec) # 사용자 발화 최대길이까지 padding\n","\n","            question_list.append(torch.tensor([q_vec]))\n","            label_list.append(torch.tensor([label]))\n","\n","        x = torch.cat(question_list)\n","        y = torch.cat(label_list)\n","\n","        # 학습용과 검증용으로 나누기\n","        x_len = x.size()[0]\n","        y_len = y.size()[0]\n","        if(x_len == y_len):\n","            train_size = int(x_len*train_ratio)\n","            \n","            train_x = x[:train_size]\n","            train_y = y[:train_size]\n","\n","            test_x = x[train_size+1:]\n","            test_y = y[train_size+1:]\n","            \n","            # TensorDataset으로 감싸기\n","            '''\n","             PyTorch의 TensorDataset은 tensor를 감싸는 Dataset입니다.\n","\n","             인덱싱 방식과 길이를 정의함으로써 이것은 tensor의 첫 번째 차원을 따라 반복, 인덱스, 슬라이스를 위한 방법을 제공합니다.\n","\n","             훈련할 때 동일한 라인에서 독립 변수와 종속 변수에 쉽게 접근할 수 있습니다.\n","            '''\n","            train_dataset = TensorDataset(train_x,train_y)\n","            test_dataset = TensorDataset(test_x,test_y)\n","            \n","            return train_dataset, test_dataset\n","            \n","        else:\n","            print(\"ERROR x!=y\")\n","            "],"id":"Ao61LhcurMyv"},{"cell_type":"code","execution_count":10,"metadata":{"id":"6VL1rzFXrMy1","executionInfo":{"status":"ok","timestamp":1643189666946,"user_tz":-540,"elapsed":681,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["dataset = MakeDataset()"],"id":"6VL1rzFXrMy1"},{"cell_type":"code","execution_count":11,"metadata":{"id":"ET7Bj003rMy2","executionInfo":{"status":"ok","timestamp":1643189670332,"user_tz":-540,"elapsed":675,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["intent_dataset = pd.read_csv(dataset.intent_data_dir)"],"id":"ET7Bj003rMy2"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"lWABy7UZrMy2","executionInfo":{"status":"ok","timestamp":1643189672362,"user_tz":-540,"elapsed":324,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"b72825c4-24d8-43a1-f425-6a222ebc5b90"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1347dcba-c712-4c1b-9440-b84b07a35362\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>야 먼지 알려주겠니</td>\n","      <td>dust</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>아니 먼지 정보 알려주세요</td>\n","      <td>dust</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>그 때 미세먼지 어떨까</td>\n","      <td>dust</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>그 때 먼지 좋으려나</td>\n","      <td>dust</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>미세먼지 어떨 것 같은데</td>\n","      <td>dust</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1347dcba-c712-4c1b-9440-b84b07a35362')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1347dcba-c712-4c1b-9440-b84b07a35362 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1347dcba-c712-4c1b-9440-b84b07a35362');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         question label\n","0      야 먼지 알려주겠니  dust\n","1  아니 먼지 정보 알려주세요  dust\n","2    그 때 미세먼지 어떨까  dust\n","3     그 때 먼지 좋으려나  dust\n","4   미세먼지 어떨 것 같은데  dust"]},"metadata":{},"execution_count":12}],"source":["intent_dataset.head()"],"id":"lWABy7UZrMy2"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"OfxGmEFDrMy5","executionInfo":{"status":"ok","timestamp":1643189676560,"user_tz":-540,"elapsed":297,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"f9074839-3f95-41eb-c4ef-aab87fb502a9"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-617ac704-54a1-40a9-bde4-adc9ca2be226\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>dust</th>\n","      <td>4997</td>\n","    </tr>\n","    <tr>\n","      <th>restaurant</th>\n","      <td>4997</td>\n","    </tr>\n","    <tr>\n","      <th>travel</th>\n","      <td>4999</td>\n","    </tr>\n","    <tr>\n","      <th>weather</th>\n","      <td>4999</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-617ac704-54a1-40a9-bde4-adc9ca2be226')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-617ac704-54a1-40a9-bde4-adc9ca2be226 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-617ac704-54a1-40a9-bde4-adc9ca2be226');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            question\n","label               \n","dust            4997\n","restaurant      4997\n","travel          4999\n","weather         4999"]},"metadata":{},"execution_count":13}],"source":["intent_dataset.groupby(['label']).count() "],"id":"OfxGmEFDrMy5"},{"cell_type":"code","execution_count":14,"metadata":{"id":"rgYxXYbLrMy6","executionInfo":{"status":"ok","timestamp":1643189829032,"user_tz":-540,"elapsed":1693,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["embed = MakeEmbed()\n","embed.load_word2vec()\n","\n","batch_size = 128\n","\n","intent_train_dataset, intent_test_dataset = dataset.make_intent_dataset(embed)\n","\n","# 한번의 iter당 Batch size의 x, y를 제공한다.\n","train_dataloader = DataLoader(intent_train_dataset, batch_size=batch_size, shuffle=True) \n","\n","test_dataloader = DataLoader(intent_test_dataset, batch_size=batch_size, shuffle=True)"],"id":"rgYxXYbLrMy6"},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxhBrB4zrMy7","executionInfo":{"status":"ok","timestamp":1643189829033,"user_tz":-540,"elapsed":20,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"1c66cbed-526e-4d7e-d261-334a4b59cd1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[   8,  226,  219,  ...,    0,    0,    0],\n","         [  40,  635, 1240,  ...,    0,    0,    0],\n","         [ 449,  171,   16,  ...,    0,    0,    0],\n","         ...,\n","         [ 289,   15,  102,  ...,    0,    0,    0],\n","         [ 190,  219,   17,  ...,    0,    0,    0],\n","         [ 431,    2,    0,  ...,    0,    0,    0]]),\n"," tensor([1, 3, 1,  ..., 3, 1, 0]))"]},"metadata":{},"execution_count":15}],"source":["intent_train_dataset.tensors"],"id":"oxhBrB4zrMy7"},{"cell_type":"markdown","metadata":{"id":"mVO3deBorMy9"},"source":["# Convolutional Neural Networks for Sentence Classification\n","## * Yoon Kim, New York University\n","### tensorflow code : https://github.com/SeonbeomKim/TensorFlow-TextCNN/blob/master/TextCNN.py"],"id":"mVO3deBorMy9"},{"cell_type":"code","execution_count":41,"metadata":{"id":"qbn_VqfQrMzE","executionInfo":{"status":"ok","timestamp":1643191972256,"user_tz":-540,"elapsed":273,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["class textCNN(nn.Module):\n","    \n","    def __init__(self, w2v, dim, kernels, dropout, num_class):\n","        super(textCNN, self).__init__()\n","        # Word2vec으로 미리 학습해둔 임베딩 적용\n","        vocab_size = w2v.size()[0]\n","        emb_dim = w2v.size()[1]\n","        self.embed = nn.Embedding(vocab_size+2, emb_dim)\n","        self.embed.weight[2:].data.copy_(w2v)\n","        # self.embed.weight.requires_grad = False # 임베딩 레이어 학습 유무\n","        \n","        # 윈도우 사이즈가 다른 각각의 conv layer 를 nn.ModuleList로 저장\n","        # nn.Conv2d(in_channels, out_channels, kernel_size)\n","        self.convs = nn.ModuleList([nn.Conv2d(1, dim, (w, emb_dim)) for w in kernels])\n","        #Dropout layer\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        #FC layer\n","        self.fc = nn.Linear(len(kernels)*dim, num_class)\n","        \n","    def forward(self, x):\n","        emb_x = self.embed(x)\n","        emb_x = emb_x.unsqueeze(1)\n","\n","        con_x = [conv(emb_x) for conv in self.convs] # 각 사이즈 별 결과를 list로 저장, \n","        print(con_x)\n","        #[(out_channels, conv결과 길이),...]\n","\n","        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x] # 각 사이즈별 max_pool 결과 저장\n","        #[(256,1),...]\n","\n","        fc_x = torch.cat(pool_x, dim=1) # concat하여 fc layer의 입력 형태로 만듬\n","        #(768,1)\n","\n","        fc_x = fc_x.squeeze(-1) # 차원 맞추기\n","        #(768)\n","        fc_x = self.dropout(fc_x)\n","        logit = self.fc(fc_x)\n","        return logit\n","\n","# 모델의 가중치 저장을 위한 코드\n","def save(model, save_dir, save_prefix, epoch):\n","    if not os.path.isdir(save_dir):\n","        os.makedirs(save_dir)\n","    save_prefix = os.path.join(save_dir, save_prefix)\n","    save_path = '{}_steps_{}.pt'.format(save_prefix, epoch)\n","    torch.save(model.state_dict(), save_path)"],"id":"qbn_VqfQrMzE"},{"cell_type":"code","execution_count":42,"metadata":{"id":"P4MeX_TwrMzG","executionInfo":{"status":"ok","timestamp":1643191976133,"user_tz":-540,"elapsed":279,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}}},"outputs":[],"source":["weights = embed.word2vec.wv.vectors # word2vec weight\n","weights = torch.FloatTensor(weights)\n","\n","num_class = len(dataset.intent_label) \n","model = textCNN(weights, 256, [3,4,5], 0.5, num_class)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"],"id":"P4MeX_TwrMzG"},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"62WPsKECrMzG","executionInfo":{"status":"error","timestamp":1643192041825,"user_tz":-540,"elapsed":283,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"a58f4d1f-4367-43e5-b674-ae7649e8053f"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'textCNN' object has no attribute 'summary'"]}],"source":["model"],"id":"62WPsKECrMzG"},{"cell_type":"markdown","metadata":{"id":"Ohvaz7fWrMzH"},"source":["# Training"],"id":"Ohvaz7fWrMzH"},{"cell_type":"code","execution_count":38,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":620},"id":"MrXolH1_rMzK","executionInfo":{"status":"error","timestamp":1643191935535,"user_tz":-540,"elapsed":83317,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"006635e8-f542-4e17-ec59-a0cef838bfad"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 0:  69%|██████▉   | 86/125 [01:22<00:37,  1.04batch/s, accuracy=97.65625, loss=0.216]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-deaf9e3179bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch = 10\\nprev_acc = 0\\nsave_dir = \"./data/pretraining/1_intent_clsf_model/\"\\nsave_prefix = \"intent_clsf\"\\nfor i in range(epoch):\\n    steps = 0\\n    model.train() \\n    #for data in train_dataloader:\\n    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\\n        for data in tepoch:\\n            tepoch.set_description(f\"Epoch {i}\")\\n            x = data[0]\\n            target = data[1]\\n            logit = model.forward(x)\\n            \\n            optimizer.zero_grad()\\n            loss = F.cross_entropy(logit, target) # loass function\\n            loss.backward()\\n            optimizer.step()\\n\\n            corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\\n            accuracy = 100.0 * corrects/x.size()[0]\\n            tepoch.set_postfix(loss=loss.item(), accuracy= accuracy.numpy())\\n            \\n    model.eval() # weight 업데이트 금지\\n    steps = 0\\n    accuarcy_list = []\\n    #for data in test_dataloader:\\n    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\\n        for data in tepoch:\\n            tepoch.set_description(f\"Epoch {i}\")\\n            x = data[0]\\n            target = data[1]\\n\\n            logit = model.forward(x)\\n            loss = F.cross_entropy(logit, target)\\n            corrects = (torch.max(logit, 1)[1].view(target.size()).data == targ...\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","epoch = 10\n","prev_acc = 0\n","save_dir = \"./data/pretraining/1_intent_clsf_model/\"\n","save_prefix = \"intent_clsf\"\n","for i in range(epoch):\n","    steps = 0\n","    model.train() \n","    #for data in train_dataloader:\n","    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n","        for data in tepoch:\n","            tepoch.set_description(f\"Epoch {i}\")\n","            x = data[0]\n","            target = data[1]\n","            logit = model.forward(x)\n","            \n","            optimizer.zero_grad()\n","            loss = F.cross_entropy(logit, target) # loass function\n","            loss.backward()\n","            optimizer.step()\n","\n","            corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n","            accuracy = 100.0 * corrects/x.size()[0]\n","            tepoch.set_postfix(loss=loss.item(), accuracy= accuracy.numpy())\n","            \n","    model.eval() # weight 업데이트 금지\n","    steps = 0\n","    accuarcy_list = []\n","    #for data in test_dataloader:\n","    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\n","        for data in tepoch:\n","            tepoch.set_description(f\"Epoch {i}\")\n","            x = data[0]\n","            target = data[1]\n","\n","            logit = model.forward(x)\n","            loss = F.cross_entropy(logit, target)\n","            corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n","            accuracy = 100.0 * corrects/x.size()[0]\n","            accuarcy_list.append(accuracy.tolist())\n","            \n","            tepoch.set_postfix(loss=loss.item(), accuracy= sum(accuarcy_list)/len(accuarcy_list))\n","    \n","    # epoch 당 검증 셋의 정확도를 계산하고 이전 정확도 보다 높으면 저장     \n","    acc = sum(accuarcy_list)/len(accuarcy_list)\n","    if(acc>prev_acc):\n","        prev_acc = acc\n","        save(model, save_dir, save_prefix+\"_\"+str(round(acc,3)), i)"],"id":"MrXolH1_rMzK"},{"cell_type":"markdown","metadata":{"id":"vkljZKEUrMzL"},"source":["# Load & Test"],"id":"vkljZKEUrMzL"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dq862HEdrMzM","executionInfo":{"status":"ok","timestamp":1643190779688,"user_tz":-540,"elapsed":1210,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"c447c24f-2ab6-4fba-bc22-6dcfa54a495e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["textCNN(\n","  (embed): Embedding(1481, 300)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))\n","    (1): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))\n","    (2): Conv2d(1, 256, kernel_size=(5, 300), stride=(1, 1))\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=768, out_features=4, bias=True)\n",")"]},"metadata":{},"execution_count":20}],"source":["model.load_state_dict(torch.load(\"./data/pretraining/save/1_intent_clsf_model/intent_clsf_97.217_steps_33.pt\"))\n","\n","model.eval()"],"id":"dq862HEdrMzM"},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEjjIfUFrMzN","executionInfo":{"status":"ok","timestamp":1643190779689,"user_tz":-540,"elapsed":12,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"66635391-3d44-4ec3-ffc2-df35ebace44d"},"outputs":[{"output_type":"stream","name":"stdout","text":["발화 : 제주도 오늘 날씨 알려줘\n","의도 : weather\n","CPU times: user 7.54 ms, sys: 1.02 ms, total: 8.56 ms\n","Wall time: 17.8 ms\n"]}],"source":["%%time\n","q = \"제주도 오늘 날씨 알려줘\"\n","\n","x = dataset.prep.pad_idx_sequencing(embed.query2idx(dataset.tokenize(q)))\n","\n","x = torch.tensor(x)\n","f = model(x.unsqueeze(0))\n","\n","intent = dataset.intents[torch.argmax(f).tolist()]\n","\n","print(\"발화 : \" + q)\n","print(\"의도 : \" + intent)"],"id":"LEjjIfUFrMzN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmtiK1RSrMzN"},"outputs":[],"source":[""],"id":"vmtiK1RSrMzN"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"1_2_intent_clsf.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}