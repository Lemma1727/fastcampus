{"cells":[{"cell_type":"markdown","metadata":{"id":"Wbz06zZ_5DB4"},"source":["# Data Processing\n","\n","## Entity recognition 테스크를 위한 데이터 처리"],"id":"Wbz06zZ_5DB4"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCVBKfv05GRv","executionInfo":{"status":"ok","timestamp":1643192330301,"user_tz":-540,"elapsed":20082,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"94167472-a9b1-4914-a2f0-abc867622bf8"},"id":"lCVBKfv05GRv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","!pwd\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25Gxi4SzutOt","executionInfo":{"status":"ok","timestamp":1643192347363,"user_tz":-540,"elapsed":1031,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"e44672d4-5a2d-49ef-c119-b82bb070ec15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","/content/drive/MyDrive/[강의자료] 한 번에 끝내는 딥러닝-인공지능 초격차 패키지 (수정, 배포 금지)_/Part 6. 딥러닝 실전 프로젝트_/Ch. 자연어 처리 실습/실습_코드/NLP_Chatbot\n","1_1_embedding.ipynb\t 2_1_NLG.ipynb\t\t\t\tchatbot.model\n","1_2_intent_clsf.ipynb\t 2_2_DialogManager.ipynb\t\tchatbot.vocab\n","1_3_entity_recog.ipynb\t 3_1_chit_chat_based_transformer.ipynb\tdata\n","1_4_ood_detection.ipynb  3_2_e2e_dialog.ipynb\t\t\tsrc\n","1_5_NLU_BASE.ipynb\t 4_1_dialog_system.ipynb\n"]}],"id":"25Gxi4SzutOt"},{"cell_type":"code","source":["!pip install torch\n","!pip install --upgrade gensim==3.4.0\n","!pip install sentencepiece\n","!pip install pytorch-crf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cY4QRYJpreUb","executionInfo":{"status":"ok","timestamp":1643192414200,"user_tz":-540,"elapsed":38754,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"c3154e34-d19d-4f77-c9c2-0219ed52e8dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Collecting gensim==3.4.0\n","  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n","\u001b[K     |████████████████████████████████| 22.2 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.19.5)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.15.0)\n","Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (5.2.1)\n","Building wheels for collected packages: gensim\n","  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gensim: filename=gensim-3.4.0-cp37-cp37m-linux_x86_64.whl size=23316670 sha256=6e8cef6f29c7fb9a61292d7210119a9a0adf4b120e6ef38bfa27f69fbc1742a0\n","  Stored in directory: /root/.cache/pip/wheels/de/a4/46/4e18f7d25915b16e0e790a5362e455aba6cadc486994806c05\n","Successfully built gensim\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-3.4.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 30.5 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting pytorch-crf\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Installing collected packages: pytorch-crf\n","Successfully installed pytorch-crf-0.7.2\n"]}],"id":"cY4QRYJpreUb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4bk_ZgM5DB-"},"outputs":[],"source":["import os\n","import sys\n","import json\n","import torch\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","\n","from tqdm import tqdm\n","from tqdm import trange\n","\n","'''\n","pip install pytorch-crf\n","https://pytorch-crf.readthedocs.io/en/stable/\n","'''\n","from torchcrf import CRF\n","\n","from torch.autograd import Variable \n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","\n","from src.dataset import Preprocessing\n","from src.model import EpochLogger, MakeEmbed, save\n","'''\n"," PyTorch의 TensorDataset은 기본적으로 x[index], y[index]를 제공합니다.\n"," 그 외에 추가로 제공하고 싶은게 있으면 아래와 같이 커스텀이 가능합니다.\n"," 여기서는 입력되는 문장의 길이를 제공 받아야해서 아래와 같이 커스텀을 하였습니다.\n","'''\n","class EntityDataset(data.Dataset):\n","    def __init__(self, x_tensor, y_tensor, lengths):\n","        super(EntityDataset, self).__init__()\n","\n","        self.x = x_tensor\n","        self.y = y_tensor\n","        self.lengths = lengths\n","        \n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index], self.lengths[index]\n","\n","    def __len__(self):\n","        return len(self.x)\n","    \n","class MakeDataset:\n","    def __init__(self):\n","        \n","        self.entity_label_dir = \"./data/dataset/entity_label.json\"\n","        self.entity_data_dir = \"./data/dataset/entity_data.csv\"\n","        \n","        self.entity_label = self.load_entity_label()\n","        self.prep = Preprocessing()\n","        \n","    def load_entity_label(self):\n","        f = open(self.entity_label_dir, encoding=\"UTF-8\")\n","        entity_label = json.loads(f.read())\n","        self.entitys = list(entity_label.keys())\n","        return entity_label\n","    \n","    \n","    def tokenize(self, sentence):\n","        return sentence.split()\n","    \n","    def tokenize_dataset(self, dataset):\n","        token_dataset = []\n","        for data in dataset:\n","            token_dataset.append(self.tokenize(data))\n","        return token_dataset\n","    \n","    def make_entity_dataset(self, embed):\n","        entity_dataset = pd.read_csv(self.entity_data_dir)\n","        entity_querys = self.tokenize_dataset(entity_dataset[\"question\"].tolist())\n","        labels = []\n","        for label in entity_dataset[\"label\"].to_list():\n","            temp = []\n","            for entity in label.split():\n","                temp.append(self.entity_label[entity])\n","            labels.append(temp)\n","        dataset = list(zip(entity_querys, labels))\n","        entity_train_dataset, entity_test_dataset = self.word2idx_dataset(dataset, embed)\n","        return entity_train_dataset, entity_test_dataset\n","    \n","    def word2idx_dataset(self, dataset ,embed, train_ratio = 0.8):\n","        embed_dataset = []\n","        question_list, label_list, lengths = [], [], []\n","        flag = True\n","        random.shuffle(dataset)\n","        for query, label in dataset :\n","            q_vec = embed.query2idx(query)\n","            lengths.append(len(q_vec))\n","            \n","            q_vec = self.prep.pad_idx_sequencing(q_vec)\n","\n","            question_list.append(torch.tensor([q_vec]))\n","\n","            label = self.prep.pad_idx_sequencing(label)\n","            label_list.append(label)\n","            flag = False\n","\n","\n","        x = torch.cat(question_list)\n","        y = torch.tensor(label_list)\n","\n","        x_len = x.size()[0]\n","        y_len = y.size()[0]\n","        if(x_len == y_len):\n","            train_size = int(x_len*train_ratio)\n","            \n","            train_x = x[:train_size]\n","            train_y = y[:train_size]\n","\n","            test_x = x[train_size+1:]\n","            test_y = y[train_size+1:]\n","\n","            train_length = lengths[:train_size]\n","            test_length = lengths[train_size+1:]\n","\n","            train_dataset = EntityDataset(train_x,train_y,train_length)\n","            test_dataset = EntityDataset(test_x,test_y,test_length)\n","            \n","            return train_dataset, test_dataset\n","            \n","        else:\n","            print(\"ERROR x!=y\")"],"id":"l4bk_ZgM5DB-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBlIO_gS5DCV"},"outputs":[],"source":["dataset = MakeDataset()"],"id":"QBlIO_gS5DCV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynkkPwTj5DCW","executionInfo":{"status":"ok","timestamp":1643192594942,"user_tz":-540,"elapsed":292,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"a9f38463-0da6-4d11-e3db-b5a3942cdbea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<START_TAG>': 15,\n"," '<STOP_TAG>': 16,\n"," 'B-DATE': 1,\n"," 'B-LOCATION': 2,\n"," 'B-PLACE': 3,\n"," 'B-RESTAURANT': 4,\n"," 'E-DATE': 5,\n"," 'E-LOCATION': 6,\n"," 'E-PLACE': 7,\n"," 'E-RESTAURANT': 8,\n"," 'I-DATE': 9,\n"," 'I-RESTAURANT': 10,\n"," 'O': 0,\n"," 'S-DATE': 11,\n"," 'S-LOCATION': 12,\n"," 'S-PLACE': 13,\n"," 'S-RESTAURANT': 14}"]},"metadata":{},"execution_count":6}],"source":["#Inside, Out, Begin, End, Single\n","#IO :  TAG라면 I 을 아니면 O 로 태그.\n","#BIO : TAG의 길이가 2이상이면 첫 번째 단어는 B를 붙이고 그 뒤의 단어들은 I를 붙인다.\n","#BIOES : BIO에서 단어의 길이가 3이상인 단어는 마지막 단어에 E를 붙인다. 그리고 단어의 길이가 1이라면, S를 붙인다.\n","# S : 단독\n","# B : 복합의 시작 (단독 사용 불가)\n","# I : 복합의 중간 (단독 사용 불가)\n","# E : 복합의 끝  (단독 사용 불가)\n","# O : 의미 없음\n","dataset.entity_label"],"id":"ynkkPwTj5DCW"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"EILdnc7N5DCZ","executionInfo":{"status":"ok","timestamp":1643192615811,"user_tz":-540,"elapsed":273,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"f77d566a-fb06-431c-ac81-73d1d29dc559"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ebaa997f-ebda-4039-8ef9-d778c6f8f9c3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>야 먼지 알려주겠니</td>\n","      <td>O O O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>아니 먼지 정보 알려주세요</td>\n","      <td>O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>그 때 미세먼지 어떨까</td>\n","      <td>O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>그 때 먼지 좋으려나</td>\n","      <td>O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>미세먼지 어떨 것 같은데</td>\n","      <td>O O O O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebaa997f-ebda-4039-8ef9-d778c6f8f9c3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ebaa997f-ebda-4039-8ef9-d778c6f8f9c3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ebaa997f-ebda-4039-8ef9-d778c6f8f9c3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         question    label\n","0      야 먼지 알려주겠니    O O O\n","1  아니 먼지 정보 알려주세요  O O O O\n","2    그 때 미세먼지 어떨까  O O O O\n","3     그 때 먼지 좋으려나  O O O O\n","4   미세먼지 어떨 것 같은데  O O O O"]},"metadata":{},"execution_count":7}],"source":["entity_dataset = pd.read_csv(dataset.entity_data_dir)\n","\n","entity_dataset.head()"],"id":"EILdnc7N5DCZ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"kkuC4E6e5DCZ","executionInfo":{"status":"ok","timestamp":1643192620049,"user_tz":-540,"elapsed":8,"user":{"displayName":"이상용","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06393511036456385624"}},"outputId":"2958ec96-2df6-49e8-9040-ed2dc67e2c7b"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-b70e6ae4-d110-4604-81f7-f0032881eb7b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>B-DATE E-DATE B-LOCATION E-LOCATION O O</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>B-DATE E-DATE O</th>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>B-DATE E-DATE O B-LOCATION E-LOCATION O O O O</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>B-DATE E-DATE O O</th>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>B-DATE E-DATE O O O</th>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>S-RESTAURANT O S-LOCATION O O</th>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>S-RESTAURANT O S-RESTAURANT O</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>S-RESTAURANT S-LOCATION O</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>S-RESTAURANT S-LOCATION O O O</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>S-RESTAURANT S-RESTAURANT O O</th>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>354 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b70e6ae4-d110-4604-81f7-f0032881eb7b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b70e6ae4-d110-4604-81f7-f0032881eb7b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b70e6ae4-d110-4604-81f7-f0032881eb7b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               question\n","label                                                  \n","B-DATE E-DATE B-LOCATION E-LOCATION O O               4\n","B-DATE E-DATE O                                       6\n","B-DATE E-DATE O B-LOCATION E-LOCATION O O O O         1\n","B-DATE E-DATE O O                                    42\n","B-DATE E-DATE O O O                                  31\n","...                                                 ...\n","S-RESTAURANT O S-LOCATION O O                         4\n","S-RESTAURANT O S-RESTAURANT O                         3\n","S-RESTAURANT S-LOCATION O                             1\n","S-RESTAURANT S-LOCATION O O O                         1\n","S-RESTAURANT S-RESTAURANT O O                         2\n","\n","[354 rows x 1 columns]"]},"metadata":{},"execution_count":8}],"source":["entity_dataset.groupby(['label']).count() "],"id":"kkuC4E6e5DCZ"},{"cell_type":"markdown","metadata":{"id":"SAppN-u55DCa"},"source":["# Bidirectional LSTM-CRF Models for Sequence Tagging\n","## * Zhiheng Huang,Wei Xu,Kai Yu\n","### tensorflow code : https://github.com/ngoquanghuy99/POS-Tagging-BiLSTM-CRF/blob/main/model.py\n","### tensorflow, keras code : https://github.com/floydhub/named-entity-recognition-template/blob/master/ner.ipynb"],"id":"SAppN-u55DCa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFOPkZ0O5DCb"},"outputs":[],"source":["class BiLSTM_CRF(nn.Module):\n","\n","    def __init__(self, w2v, tag_to_ix, hidden_dim, batch_size):\n","        super(BiLSTM_CRF, self).__init__()\n","        self.embedding_dim = w2v.size()[1]\n","        self.hidden_dim = hidden_dim\n","        self.vocab_size =  w2v.size()[0]\n","        self.tag_to_ix = tag_to_ix\n","        self.tagset_size = len(tag_to_ix)\n","        self.batch_size = batch_size\n","        self.START_TAG = \"<START_TAG>\"\n","        self.STOP_TAG = \"<STOP_TAG>\"\n","        \n","        self.word_embeds = nn.Embedding(self.vocab_size+2, self.embedding_dim)\n","        self.word_embeds.weight[2:].data.copy_(w2v)\n","        #self.word_embeds.weight.requires_grad = False\n","        \n","        # LSTM 파라미터 정의\n","        # bidirectional : 양방향 LSTM\n","        # num_layers    : layer의 수\n","        # batch_first   : pytorch에서 LSTM 입력의 기본값은 (Length,batch,Hidden) 순서 이므로 (batch,Length,Hidden)로 바꿔주기 위함\n","        # nn.LSTM(input_size, hidden_size, batch_first, num_layers)\n","        # hidden_size = hidden_dim // 2 인 이유는 bidirectional = True 이기 떄문입니다.\n","        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim // 2, batch_first=True, num_layers=1, bidirectional=True)\n","    \n","        # LSTM의 출력을 태그 공간으로 대응시킵니다.\n","        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n","    \n","        self.hidden = self.init_hidden()\n","        \n","        # 출력층의 규칙학습을 위한 CRF 세팅\n","        self.crf = CRF(self.tagset_size, batch_first=True)\n","        \n","    def init_hidden(self):#(h,c)\n","        return (torch.randn(2, self.batch_size, self.hidden_dim // 2),\n","                torch.randn(2, self.batch_size, self.hidden_dim // 2))\n","\n","    def forward(self, sentence):\n","        # Bi-LSTM으로부터 배출 점수를 얻습니다.\n","        self.batch_size = sentence.size()[0]\n","        self.hidden = self.init_hidden()\n","        #(2,128,128),(2,128,128)\n","        embeds = self.word_embeds(sentence)\n","        #(128,20,300)\n","        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n","        #(128,20,256),((2,128,128),(2,128,128))\n","        lstm_feats = self.hidden2tag(lstm_out)#(batch, length,tagset_size)\n","        #(128,20,17)\n","        return lstm_feats\n","    \n","    def decode(self, logits, mask):\n","        \"\"\"\n","        Viterbi Decoding의 구현체입니다.\n","        CRF 레이어의 출력을 prediction으로 변형합니다.\n","        :param logits: 모델의 출력 (로짓)\n","        :param mask: 마스킹 벡터\n","        :return: 모델의 예측 (prediction)\n","        \n","        각 단어의 자리마다\n","          word 1의 태그 확률        |  word2의 태그 확률\n","         'O': 확률0,              | 'O': 확률A,\n","         'B-DATE': 확률1,         | 'B-DATE': 확률B\n","         'B-LOCATION': 확률2,     | 'B-LOCATION': 확률C,\n","         'B-PLACE': 확률3,        | 'B-PLACE': 확률D,  \n","         'B-RESTAURANT': 확률4,   | 'B-RESTAURANT': 확률E,  \n","         'E-DATE': 확률5,         | 'E-DATE': 확률F,   \n","         'E-LOCATION': 확률6,     | 'E-LOCATION': 확률G, \n","         'E-PLACE': 확률7,        | 'E-PLACE': 확률H,  \n","         'E-RESTAURANT': 확률8,   | 'E-RESTAURANT': 확률I, \n","         'I-DATE': 확률9,         | 'I-DATE': 확률J,    \n","         'I-RESTAURANT': 확률10,  | 'I-RESTAURANT': 확률K,\n","         'S-DATE': 확률11,        | 'S-DATE': 확률L,      \n","         'S-LOCATION': 확률12,    | 'S-LOCATION': 확률M,\n","         'S-PLACE': 확률13,       | 'S-PLACE': 확률N,  \n","         'S-RESTAURANT': 확률14,  | 'S-RESTAURANT': 확률O,\n","         '<START_TAG>': 확률15,   | '<START_TAG>': 확률P, \n","         '<STOP_TAG>': 확률15,    | '<STOP_TAG>': 확률Q,\n","         \n","         각각의 높은 확률을 뽑는 것은 보통의 딥러닝 방식으로 B단독이나 I단독, E단독같은 문제를 야기할 수 있습니다.\n","         태그들의 확률 값을 받아서 \n","         CRF는 태그들의 의존성을 학습할수 있어서 태그 시퀀스의 확률이 가장 높은 확률을 가지는 예측 시퀀스를 선택한다.\n","         그래서 B단독이나 I단독, E단독과 같은 문제를 없애줍니다.\n","         예를 들어 B-DATE, O 와 같은걸 출력하지 않습니다. (CRF는 S-DATE, O 라고 출력합니다.)\n","        \"\"\"\n","\n","        return self.crf.decode(logits, mask)\n","    \n","    def compute_loss(self, label, logits, mask):\n","        \"\"\"\n","        학습을 위한 total loss를 계산합니다.\n","        :param label: label\n","        :param logits: logits\n","        :param mask: mask vector\n","        :return: total loss\n","        \"\"\"\n","\n","        log_likelihood = self.crf(logits, label, mask=mask, reduction='mean')\n","        return - log_likelihood  # Negative log likelihood loss\n","    \n"],"id":"wFOPkZ0O5DCb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KD7oiQVB5DCd"},"outputs":[],"source":["embed = MakeEmbed()\n","embed.load_word2vec()\n","\n","entity_train_dataset, entity_test_dataset = dataset.make_entity_dataset(embed)\n","\n","train_dataloader = DataLoader(entity_train_dataset, batch_size=128, shuffle=True)\n","\n","test_dataloader = DataLoader(entity_test_dataset, batch_size=128, shuffle=True)"],"id":"KD7oiQVB5DCd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eu3-W29H5DCe","outputId":"04c4d945-a8d6-48cf-a1c4-f3b992caec15"},"outputs":[{"data":{"text/plain":["tensor([[233,   2, 765,  ...,   0,   0,   0],\n","        [399,   2, 488,  ...,   0,   0,   0],\n","        [322, 192,   0,  ...,   0,   0,   0],\n","        ...,\n","        [239,  53, 117,  ...,   0,   0,   0],\n","        [  2, 233, 678,  ...,   0,   0,   0],\n","        [429, 109,  10,  ...,   0,   0,   0]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["entity_train_dataset.x"],"id":"eu3-W29H5DCe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sc4FW0e05DCh","outputId":"55207213-b16f-4f66-b7a0-2a66f52b6f20"},"outputs":[{"data":{"text/plain":["tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n","        [11,  0,  0,  ...,  0,  0,  0],\n","        [12,  0,  0,  ...,  0,  0,  0],\n","        ...,\n","        [ 0, 13,  0,  ...,  0,  0,  0],\n","        [ 0,  0,  0,  ...,  0,  0,  0],\n","        [12,  0,  0,  ...,  0,  0,  0]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["entity_train_dataset.y"],"id":"Sc4FW0e05DCh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaD95Hj_5DCl","outputId":"a50b5c27-8120-42ea-cde9-1d762165b83e"},"outputs":[{"data":{"text/plain":["BiLSTM_CRF(\n","  (word_embeds): Embedding(1481, 300)\n","  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n","  (hidden2tag): Linear(in_features=256, out_features=17, bias=True)\n","  (crf): CRF(num_tags=17)\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["weights = embed.word2vec.wv.vectors\n","weights = torch.FloatTensor(weights)\n","\n","model = BiLSTM_CRF(weights, dataset.entity_label, 256, 128)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","model.train()"],"id":"iaD95Hj_5DCl"},{"cell_type":"markdown","metadata":{"id":"ZeTirETL5DCr"},"source":["# Training"],"id":"ZeTirETL5DCr"},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"9q32CePf5DCs","outputId":"63239480-ad2a-4cb1-f59c-69370ffec9ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 0: 100%|██████████| 125/125 [00:25<00:00,  4.89batch/s, loss=2.56]\n","Epoch 0: 100%|██████████| 32/32 [00:02<00:00, 12.97batch/s, accuracy=51.1, loss=2.54]\n","Epoch 1:  38%|███▊      | 48/125 [00:19<00:31,  2.42batch/s, loss=0.835]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-3c9c64110918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epoch = 5\n","prev_acc = 0\n","save_dir = \"./data/pretraining/1_entity_recog_model/\"\n","save_prefix = \"entity_recog\"\n","for i in range(epoch):\n","    steps = 0\n","    model.train()\n","    #for data in train_dataloader:\n","    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n","        for data in tepoch:\n","            tepoch.set_description(f\"Epoch {i}\")\n","            x = data[0]\n","            y = data[1]\n","            length = data[2]\n","            \n","            logits = model.forward(x)\n","            # padding 된 부분을 마스킹하기위한 코드\n","            # 우리는 length값이 존재하여 length값을 이용해서 마스크를 생성해도 가능\n","            # 하지만 코드 간략화를 위해 pytorch에 where 함수를 이용해 마스크 생성\n","            # torch.where 함수 설명 : https://runebook.dev/ko/docs/pytorch/generated/torch.where\n","            mask = torch.where(x > 0, torch.tensor([1.]), torch.tensor([0.])).type(torch.uint8)\n","            loss = model.compute_loss(y,logits,mask)\n","            \n","            loss.backward()\n","            optimizer.step()\n","\n","            tepoch.set_postfix(loss=loss.item())\n","            \n","    model.eval()\n","    steps = 0\n","    accuarcy_list = []\n","    #for data in test_dataloader:\n","    with tqdm(test_dataloader, unit=\"batch\") as tepoch:\n","        for data in tepoch:\n","            tepoch.set_description(f\"Epoch {i}\")\n","            x = data[0]\n","            y = data[1]\n","            length = data[2]\n","            \n","            mask = torch.where(x > 0, torch.tensor([1.]), torch.tensor([0.])).type(torch.uint8)\n","            logits = model.forward(x)\n","            \n","            predicts = model.decode(logits,mask)\n","            # decode함수를 통해 정확도 계산\n","            corrects = []\n","            for target, leng, predict in zip(y, length, predicts):\n","                corrects.append(target[:leng].tolist() == predict)\n","\n","            accuracy = 100.0 * sum(corrects)/len(corrects)\n","            accuarcy_list.append(accuracy)\n","            \n","            loss = model.compute_loss(y,logits,mask)\n","            tepoch.set_postfix(loss=loss.item(), accuracy= sum(accuarcy_list)/len(accuarcy_list))\n","            \n","        acc = sum(accuarcy_list)/len(accuarcy_list)\n","        if(acc>prev_acc):\n","            prev_acc = acc\n","            save(model, save_dir, save_prefix+\"_\"+str(round(acc,3)), i)"],"id":"9q32CePf5DCs"},{"cell_type":"markdown","metadata":{"id":"3EbTOZdR5DCv"},"source":["# Load & Test"],"id":"3EbTOZdR5DCv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQ7-y73v5DCv","outputId":"b5d544e1-74ca-4f2e-a025-59716ae2c770"},"outputs":[{"data":{"text/plain":["BiLSTM_CRF(\n","  (word_embeds): Embedding(1481, 300)\n","  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n","  (hidden2tag): Linear(in_features=256, out_features=17, bias=True)\n","  (crf): CRF(num_tags=17)\n",")"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"./data/pretraining/save/1_entity_recog_model/entity_recog_97.192_steps_7.pt\"))\n","\n","model.eval()"],"id":"BQ7-y73v5DCv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5a7o1GF5DCw","outputId":"a73e19a5-6eee-4d18-c5de-151a30883288"},"outputs":[{"name":"stdout","output_type":"stream","text":["단어 : 이번 , 태그 : B-DATE\n","단어 : 주 , 태그 : E-DATE\n","단어 : 날씨 , 태그 : O\n","CPU times: user 7.08 ms, sys: 2.93 ms, total: 10 ms\n","Wall time: 7.07 ms\n"]}],"source":["%%time\n","q = \"이번 주 날씨\"\n","x = dataset.prep.pad_idx_sequencing(embed.query2idx(dataset.tokenize(q)))\n","\n","x = torch.tensor(x)\n","f = model(x.unsqueeze(0))\n","\n","mask = torch.where(x > 0, torch.tensor([1.]), torch.tensor([0.])).type(torch.uint8)\n","\n","predict = model.decode(f,mask.view(1,-1))\n","\n","# S : 단독\n","# B : 복합의 시작\n","# I : 복합의 중간\n","# E : 복합의 끝\n","tag = [dataset.entitys[p] for p in predict[0]]\n","for i, j in zip(q.split(' '),tag):\n","    print(\"단어 : \"+i+\" , \"+\"태그 : \"+j)"],"id":"k5a7o1GF5DCw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hsM0sN85DCx","outputId":"11de320f-a78d-4671-ede0-75f427eae969"},"outputs":[{"name":"stdout","output_type":"stream","text":["단어 : 나 , 태그 : O\n","단어 : 내일 , 태그 : S-DATE\n","단어 : 제주도 , 태그 : S-LOCATION\n","단어 : 여행 , 태그 : O\n","단어 : 가는데 , 태그 : O\n","단어 : 미세먼지 , 태그 : O\n","단어 : 알려줘 , 태그 : O\n","CPU times: user 9.67 ms, sys: 2.53 ms, total: 12.2 ms\n","Wall time: 12.1 ms\n"]}],"source":["%%time\n","q = \"나 내일 제주도 여행 가는데 미세먼지 알려줘\"\n","x = dataset.prep.pad_idx_sequencing(embed.query2idx(dataset.tokenize(q)))\n","\n","x = torch.tensor(x)\n","f = model(x.unsqueeze(0))\n","\n","mask = torch.where(x > 0, torch.tensor([1.]), torch.tensor([0.])).type(torch.uint8)\n","\n","predict = model.decode(f,mask.view(1,-1))\n","\n","# S : 단독\n","# B : 복합의 시작\n","# I : 복합의 중간\n","# E : 복합의 끝\n","tag = [dataset.entitys[p] for p in predict[0]]\n","for i, j in zip(q.split(' '),tag):\n","    print(\"단어 : \"+i+\" , \"+\"태그 : \"+j)"],"id":"-hsM0sN85DCx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlbW94SE5DCy"},"outputs":[],"source":[""],"id":"UlbW94SE5DCy"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"1_3_entity_recog.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}